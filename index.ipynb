{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Neural Networks with Regularization - Lab \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll use a train-test partition as well as a validation set to get better insights about how to tune neural networks using regularization techniques. You'll start by repeating the process from the last section: importing the data and performing preprocessing including one-hot encoding. From there, you'll define and compile the model like before. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Apply early stopping criteria with a neural network \n",
    "- Apply L1, L2, and dropout regularization on a neural network  \n",
    "- Examine the effects of training with more data on a neural network  \n",
    "\n",
    "\n",
    "## Load the Data\n",
    "\n",
    "Run the following cell to import some of the libraries and classes you'll need in this lab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in the file `'Bank_complaints.csv'`. Load and preview the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preview the dataset\n",
    "df = pd.read_csv('Bank_complaints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>In XX/XX/XXXX I filled out the Fedlaon applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I am being contacted by a debt collector for p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>I cosigned XXXX student loans at SallieMae for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>Navient has sytematically and illegally failed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Student loan</td>\n",
       "      <td>My wife became eligible for XXXX Loan Forgiven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Product                       Consumer complaint narrative\n",
       "0  Student loan  In XX/XX/XXXX I filled out the Fedlaon applica...\n",
       "1  Student loan  I am being contacted by a debt collector for p...\n",
       "2  Student loan  I cosigned XXXX student loans at SallieMae for...\n",
       "3  Student loan  Navient has sytematically and illegally failed...\n",
       "4  Student loan  My wife became eligible for XXXX Loan Forgiven..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 2 columns):\n",
      " #   Column                        Non-Null Count  Dtype \n",
      "---  ------                        --------------  ----- \n",
      " 0   Product                       60000 non-null  object\n",
      " 1   Consumer complaint narrative  60000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Overview\n",
    "\n",
    "Before you begin to practice some of your new tools such as regularization and optimization, let's practice munging some data as you did in the previous section with bank complaints. Recall some techniques:\n",
    "\n",
    "* Sampling in order to reduce training time (investigate model accuracy vs data size later on)\n",
    "* Train - test split\n",
    "* One-hot encoding your complaint text\n",
    "* Transforming your category labels \n",
    "\n",
    "## Preprocessing: Generate a Random Sample\n",
    "\n",
    "Since you have quite a bit of data and training neural networks takes a substantial amount of time and resources, downsample in order to test your initial pipeline. Going forward, these can be interesting areas of investigation: how does your model's performance change as you increase (or decrease) the size of your dataset?  \n",
    "\n",
    "- Generate a random sample of 10,000 observations using seed 123 for consistency of results. \n",
    "- Split this sample into `X` and `y` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "df_sample = df.sample(10000, random_state=123)\n",
    "\n",
    "# Split the data into X and y\n",
    "y = df['Product']\n",
    "X = df['Consumer complaint narrative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "- Split the data into training and test sets \n",
    "- Assign 1500 obervations to the test set and use 42 as the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1500, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation set \n",
    "\n",
    "As mentioned in the previous lesson, it is good practice to set aside a validation set, which is then used during hyperparameter tuning. Afterwards, when you have decided upon a final model, the test set can then be used to determine an unbiased perforance of the model. \n",
    "\n",
    "Run the cell below to further divide the training data into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(X_train, y_train, test_size=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: One-hot Encoding the Complaints\n",
    "\n",
    "As before, you need to do some preprocessing before building a neural network model. \n",
    "\n",
    "- Keep the 2,000 most common words and use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "- Transform the training, validate, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use one-hot encoding to reformat the complaints into a matrix of vectors \n",
    "# Only keep the 2000 most common words \n",
    "\n",
    "tokenizer = Tokenizer(num_words=2000,\n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "\n",
    "# fit on train_final data\n",
    "tokenizer.fit_on_texts(X_train_final)\n",
    "\n",
    "# transform datasets\n",
    "X_train_tokens = tokenizer.texts_to_matrix(X_train_final, mode='binary')\n",
    "X_val_tokens = tokenizer.texts_to_matrix(X_val, mode='binary')\n",
    "X_test_tokens = tokenizer.texts_to_matrix(X_test, mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57500, 2000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing: Encoding the Products\n",
    "\n",
    "Similarly, now transform the descriptive product labels to integers labels. After transforming them to integer labels, retransform them into a matrix of binary flags, one for each of the various product labels.  \n",
    "  \n",
    "> **Note**: This is similar to your previous work with dummy variables. Each of the various product categories will be its own column, and each observation will be a row. In turn, each of these observation rows will have a 1 in the column associated with it's label, and all other entries for the row will be zero. \n",
    "\n",
    "Transform the training, validate, and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the product labels to numerical values\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final)\n",
    "\n",
    "y_train_lb = lb.transform(y_train_final)\n",
    "y_val_lb = lb.transform(y_val)\n",
    "y_test_lb = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Baseline Model \n",
    "\n",
    "Rebuild a fully connected (Dense) layer network:  \n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions (since you are dealing with a multiclass problem, classifying the complaints into 7 classes) \n",
    "- Use a `'softmax'` activation function for the output layer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a baseline neural network model using Keras\n",
    "random.seed(123)\n",
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "baseline_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "baseline_model.add(layers.Dense(25, activation='relu'))\n",
    "baseline_model.add(layers.Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model\n",
    "\n",
    "Compile this model with: \n",
    "\n",
    "- a stochastic gradient descent optimizer \n",
    "- `'categorical_crossentropy'` as the loss function \n",
    "- a focus on `'accuracy'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(optimizer='sgd',\n",
    "                       loss='categorical_crossentropy',\n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "- Train the model for 150 epochs in mini-batches of 256 samples \n",
    "- Include the `validation_data` argument to ensure you keep track of the validation loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.8270 - accuracy: 0.2705 - val_loss: 1.7060 - val_accuracy: 0.3740\n",
      "Epoch 2/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.4951 - accuracy: 0.5035 - val_loss: 1.3180 - val_accuracy: 0.5980\n",
      "Epoch 3/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.1481 - accuracy: 0.6498 - val_loss: 1.0157 - val_accuracy: 0.6720\n",
      "Epoch 4/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9146 - accuracy: 0.7067 - val_loss: 0.8482 - val_accuracy: 0.7190\n",
      "Epoch 5/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7847 - accuracy: 0.7321 - val_loss: 0.7559 - val_accuracy: 0.7390\n",
      "Epoch 6/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7127 - accuracy: 0.7493 - val_loss: 0.7069 - val_accuracy: 0.7450\n",
      "Epoch 7/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6684 - accuracy: 0.7611 - val_loss: 0.6756 - val_accuracy: 0.7530\n",
      "Epoch 8/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6375 - accuracy: 0.7706 - val_loss: 0.6520 - val_accuracy: 0.7650\n",
      "Epoch 9/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6144 - accuracy: 0.7777 - val_loss: 0.6354 - val_accuracy: 0.7740\n",
      "Epoch 10/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5956 - accuracy: 0.7836 - val_loss: 0.6207 - val_accuracy: 0.7760\n",
      "Epoch 11/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5803 - accuracy: 0.7889 - val_loss: 0.6119 - val_accuracy: 0.7760\n",
      "Epoch 12/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5668 - accuracy: 0.7947 - val_loss: 0.6019 - val_accuracy: 0.7840\n",
      "Epoch 13/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5550 - accuracy: 0.7994 - val_loss: 0.5967 - val_accuracy: 0.7840\n",
      "Epoch 14/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5446 - accuracy: 0.8031 - val_loss: 0.5880 - val_accuracy: 0.7880\n",
      "Epoch 15/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5350 - accuracy: 0.8069 - val_loss: 0.5846 - val_accuracy: 0.7920\n",
      "Epoch 16/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5266 - accuracy: 0.8105 - val_loss: 0.5776 - val_accuracy: 0.7970\n",
      "Epoch 17/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5186 - accuracy: 0.8131 - val_loss: 0.5784 - val_accuracy: 0.7920\n",
      "Epoch 18/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5112 - accuracy: 0.8157 - val_loss: 0.5723 - val_accuracy: 0.7950\n",
      "Epoch 19/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5043 - accuracy: 0.8194 - val_loss: 0.5718 - val_accuracy: 0.7970\n",
      "Epoch 20/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4981 - accuracy: 0.8214 - val_loss: 0.5655 - val_accuracy: 0.8010\n",
      "Epoch 21/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4920 - accuracy: 0.8241 - val_loss: 0.5631 - val_accuracy: 0.8040\n",
      "Epoch 22/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4865 - accuracy: 0.8262 - val_loss: 0.5668 - val_accuracy: 0.7940\n",
      "Epoch 23/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4814 - accuracy: 0.8287 - val_loss: 0.5695 - val_accuracy: 0.7910\n",
      "Epoch 24/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4765 - accuracy: 0.8297 - val_loss: 0.5594 - val_accuracy: 0.7980\n",
      "Epoch 25/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4717 - accuracy: 0.8324 - val_loss: 0.5570 - val_accuracy: 0.7990\n",
      "Epoch 26/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.8340 - val_loss: 0.5630 - val_accuracy: 0.7900\n",
      "Epoch 27/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4632 - accuracy: 0.8350 - val_loss: 0.5549 - val_accuracy: 0.8010\n",
      "Epoch 28/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4591 - accuracy: 0.8369 - val_loss: 0.5568 - val_accuracy: 0.7980\n",
      "Epoch 29/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4553 - accuracy: 0.8384 - val_loss: 0.5533 - val_accuracy: 0.8020\n",
      "Epoch 30/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4517 - accuracy: 0.8409 - val_loss: 0.5543 - val_accuracy: 0.8020\n",
      "Epoch 31/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4484 - accuracy: 0.8408 - val_loss: 0.5513 - val_accuracy: 0.7980\n",
      "Epoch 32/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4448 - accuracy: 0.8424 - val_loss: 0.5501 - val_accuracy: 0.8040\n",
      "Epoch 33/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4414 - accuracy: 0.8441 - val_loss: 0.5520 - val_accuracy: 0.8020\n",
      "Epoch 34/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4383 - accuracy: 0.8451 - val_loss: 0.5498 - val_accuracy: 0.8040\n",
      "Epoch 35/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4356 - accuracy: 0.8468 - val_loss: 0.5518 - val_accuracy: 0.7940\n",
      "Epoch 36/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4326 - accuracy: 0.8468 - val_loss: 0.5502 - val_accuracy: 0.8050\n",
      "Epoch 37/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4301 - accuracy: 0.8485 - val_loss: 0.5477 - val_accuracy: 0.7990\n",
      "Epoch 38/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4273 - accuracy: 0.8498 - val_loss: 0.5509 - val_accuracy: 0.8030\n",
      "Epoch 39/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4246 - accuracy: 0.8501 - val_loss: 0.5534 - val_accuracy: 0.7950\n",
      "Epoch 40/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4221 - accuracy: 0.8516 - val_loss: 0.5507 - val_accuracy: 0.8020\n",
      "Epoch 41/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4198 - accuracy: 0.8523 - val_loss: 0.5494 - val_accuracy: 0.8040\n",
      "Epoch 42/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4176 - accuracy: 0.8525 - val_loss: 0.5513 - val_accuracy: 0.8010\n",
      "Epoch 43/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4151 - accuracy: 0.8541 - val_loss: 0.5520 - val_accuracy: 0.7960\n",
      "Epoch 44/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4129 - accuracy: 0.8549 - val_loss: 0.5521 - val_accuracy: 0.8060\n",
      "Epoch 45/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.4108 - accuracy: 0.8553 - val_loss: 0.5549 - val_accuracy: 0.7970\n",
      "Epoch 46/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.4086 - accuracy: 0.8564 - val_loss: 0.5510 - val_accuracy: 0.8000\n",
      "Epoch 47/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.4068 - accuracy: 0.8565 - val_loss: 0.5582 - val_accuracy: 0.8010\n",
      "Epoch 48/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.4047 - accuracy: 0.8586 - val_loss: 0.5523 - val_accuracy: 0.8100\n",
      "Epoch 49/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4027 - accuracy: 0.8589 - val_loss: 0.5543 - val_accuracy: 0.8050\n",
      "Epoch 50/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.4006 - accuracy: 0.8589 - val_loss: 0.5520 - val_accuracy: 0.8010\n",
      "Epoch 51/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3991 - accuracy: 0.8590 - val_loss: 0.5596 - val_accuracy: 0.8020\n",
      "Epoch 52/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3973 - accuracy: 0.8603 - val_loss: 0.5588 - val_accuracy: 0.8010\n",
      "Epoch 53/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3957 - accuracy: 0.8608 - val_loss: 0.5552 - val_accuracy: 0.8020\n",
      "Epoch 54/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3939 - accuracy: 0.8612 - val_loss: 0.5615 - val_accuracy: 0.8010\n",
      "Epoch 55/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3924 - accuracy: 0.8620 - val_loss: 0.5556 - val_accuracy: 0.8040\n",
      "Epoch 56/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3908 - accuracy: 0.8622 - val_loss: 0.5607 - val_accuracy: 0.7960\n",
      "Epoch 57/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3888 - accuracy: 0.8625 - val_loss: 0.5590 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3874 - accuracy: 0.8635 - val_loss: 0.5602 - val_accuracy: 0.7930\n",
      "Epoch 59/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3860 - accuracy: 0.8639 - val_loss: 0.5583 - val_accuracy: 0.7960\n",
      "Epoch 60/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3844 - accuracy: 0.8644 - val_loss: 0.5595 - val_accuracy: 0.7970\n",
      "Epoch 61/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3830 - accuracy: 0.8645 - val_loss: 0.5640 - val_accuracy: 0.7980\n",
      "Epoch 62/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3813 - accuracy: 0.8655 - val_loss: 0.5634 - val_accuracy: 0.7990\n",
      "Epoch 63/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3802 - accuracy: 0.8660 - val_loss: 0.5621 - val_accuracy: 0.7990\n",
      "Epoch 64/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3785 - accuracy: 0.8667 - val_loss: 0.5649 - val_accuracy: 0.7960\n",
      "Epoch 65/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3771 - accuracy: 0.8671 - val_loss: 0.5615 - val_accuracy: 0.7960\n",
      "Epoch 66/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3757 - accuracy: 0.8669 - val_loss: 0.5674 - val_accuracy: 0.7960\n",
      "Epoch 67/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3747 - accuracy: 0.8681 - val_loss: 0.5669 - val_accuracy: 0.7970\n",
      "Epoch 68/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3733 - accuracy: 0.8680 - val_loss: 0.5688 - val_accuracy: 0.8010\n",
      "Epoch 69/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3717 - accuracy: 0.8686 - val_loss: 0.5670 - val_accuracy: 0.7940\n",
      "Epoch 70/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3707 - accuracy: 0.8694 - val_loss: 0.5641 - val_accuracy: 0.7950\n",
      "Epoch 71/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3694 - accuracy: 0.8697 - val_loss: 0.5661 - val_accuracy: 0.7970\n",
      "Epoch 72/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3683 - accuracy: 0.8703 - val_loss: 0.5734 - val_accuracy: 0.8010\n",
      "Epoch 73/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3669 - accuracy: 0.8699 - val_loss: 0.5742 - val_accuracy: 0.7910\n",
      "Epoch 74/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3656 - accuracy: 0.8712 - val_loss: 0.5713 - val_accuracy: 0.7990\n",
      "Epoch 75/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3644 - accuracy: 0.8719 - val_loss: 0.5806 - val_accuracy: 0.7980\n",
      "Epoch 76/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3633 - accuracy: 0.8717 - val_loss: 0.5712 - val_accuracy: 0.7990\n",
      "Epoch 77/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3619 - accuracy: 0.8724 - val_loss: 0.5847 - val_accuracy: 0.8000\n",
      "Epoch 78/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3611 - accuracy: 0.8726 - val_loss: 0.5725 - val_accuracy: 0.8000\n",
      "Epoch 79/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3599 - accuracy: 0.8740 - val_loss: 0.5758 - val_accuracy: 0.7980\n",
      "Epoch 80/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3585 - accuracy: 0.8735 - val_loss: 0.5816 - val_accuracy: 0.8000\n",
      "Epoch 81/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3576 - accuracy: 0.8737 - val_loss: 0.5753 - val_accuracy: 0.7990\n",
      "Epoch 82/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3561 - accuracy: 0.8746 - val_loss: 0.5792 - val_accuracy: 0.8000\n",
      "Epoch 83/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3554 - accuracy: 0.8752 - val_loss: 0.5758 - val_accuracy: 0.7990\n",
      "Epoch 84/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3544 - accuracy: 0.8754 - val_loss: 0.5831 - val_accuracy: 0.7910\n",
      "Epoch 85/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3534 - accuracy: 0.8758 - val_loss: 0.5788 - val_accuracy: 0.7990\n",
      "Epoch 86/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3523 - accuracy: 0.8759 - val_loss: 0.5871 - val_accuracy: 0.8020\n",
      "Epoch 87/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3512 - accuracy: 0.8768 - val_loss: 0.5815 - val_accuracy: 0.8050\n",
      "Epoch 88/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3502 - accuracy: 0.8767 - val_loss: 0.5820 - val_accuracy: 0.7990\n",
      "Epoch 89/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3488 - accuracy: 0.8769 - val_loss: 0.5916 - val_accuracy: 0.8060\n",
      "Epoch 90/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3478 - accuracy: 0.8778 - val_loss: 0.5837 - val_accuracy: 0.8020\n",
      "Epoch 91/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3470 - accuracy: 0.8785 - val_loss: 0.5921 - val_accuracy: 0.7950\n",
      "Epoch 92/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3457 - accuracy: 0.8778 - val_loss: 0.5968 - val_accuracy: 0.8000\n",
      "Epoch 93/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3450 - accuracy: 0.8785 - val_loss: 0.5903 - val_accuracy: 0.8000\n",
      "Epoch 94/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3438 - accuracy: 0.8788 - val_loss: 0.5931 - val_accuracy: 0.8020\n",
      "Epoch 95/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3427 - accuracy: 0.8801 - val_loss: 0.5889 - val_accuracy: 0.8050\n",
      "Epoch 96/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3419 - accuracy: 0.8805 - val_loss: 0.5914 - val_accuracy: 0.8060\n",
      "Epoch 97/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3410 - accuracy: 0.8806 - val_loss: 0.5902 - val_accuracy: 0.8020\n",
      "Epoch 98/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3399 - accuracy: 0.8811 - val_loss: 0.5918 - val_accuracy: 0.7980\n",
      "Epoch 99/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3389 - accuracy: 0.8816 - val_loss: 0.5977 - val_accuracy: 0.8010\n",
      "Epoch 100/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3382 - accuracy: 0.8815 - val_loss: 0.5996 - val_accuracy: 0.8040\n",
      "Epoch 101/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3369 - accuracy: 0.8813 - val_loss: 0.6037 - val_accuracy: 0.7970\n",
      "Epoch 102/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3360 - accuracy: 0.8826 - val_loss: 0.5957 - val_accuracy: 0.8050\n",
      "Epoch 103/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3348 - accuracy: 0.8831 - val_loss: 0.5955 - val_accuracy: 0.8000\n",
      "Epoch 104/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3339 - accuracy: 0.8827 - val_loss: 0.5958 - val_accuracy: 0.8030\n",
      "Epoch 105/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3329 - accuracy: 0.8841 - val_loss: 0.5999 - val_accuracy: 0.7960\n",
      "Epoch 106/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3323 - accuracy: 0.8838 - val_loss: 0.6015 - val_accuracy: 0.8010\n",
      "Epoch 107/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3314 - accuracy: 0.8839 - val_loss: 0.5998 - val_accuracy: 0.8010\n",
      "Epoch 108/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3303 - accuracy: 0.8845 - val_loss: 0.6045 - val_accuracy: 0.7950\n",
      "Epoch 109/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3293 - accuracy: 0.8852 - val_loss: 0.6100 - val_accuracy: 0.7980\n",
      "Epoch 110/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3283 - accuracy: 0.8858 - val_loss: 0.6071 - val_accuracy: 0.7940\n",
      "Epoch 111/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3272 - accuracy: 0.8858 - val_loss: 0.6094 - val_accuracy: 0.7980\n",
      "Epoch 112/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3260 - accuracy: 0.8860 - val_loss: 0.6103 - val_accuracy: 0.8010\n",
      "Epoch 113/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3253 - accuracy: 0.8865 - val_loss: 0.6052 - val_accuracy: 0.8040\n",
      "Epoch 114/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3243 - accuracy: 0.8865 - val_loss: 0.6070 - val_accuracy: 0.8040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3232 - accuracy: 0.8875 - val_loss: 0.6133 - val_accuracy: 0.8050\n",
      "Epoch 116/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3224 - accuracy: 0.8869 - val_loss: 0.6076 - val_accuracy: 0.8030\n",
      "Epoch 117/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3212 - accuracy: 0.8880 - val_loss: 0.6157 - val_accuracy: 0.8000\n",
      "Epoch 118/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3201 - accuracy: 0.8892 - val_loss: 0.6132 - val_accuracy: 0.7970\n",
      "Epoch 119/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3195 - accuracy: 0.8889 - val_loss: 0.6133 - val_accuracy: 0.8030\n",
      "Epoch 120/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3186 - accuracy: 0.8893 - val_loss: 0.6167 - val_accuracy: 0.8060\n",
      "Epoch 121/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3178 - accuracy: 0.8896 - val_loss: 0.6177 - val_accuracy: 0.7970\n",
      "Epoch 122/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3166 - accuracy: 0.8903 - val_loss: 0.6206 - val_accuracy: 0.8070\n",
      "Epoch 123/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3156 - accuracy: 0.8905 - val_loss: 0.6187 - val_accuracy: 0.7990\n",
      "Epoch 124/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3145 - accuracy: 0.8916 - val_loss: 0.6159 - val_accuracy: 0.8030\n",
      "Epoch 125/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3136 - accuracy: 0.8915 - val_loss: 0.6166 - val_accuracy: 0.8020\n",
      "Epoch 126/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3124 - accuracy: 0.8922 - val_loss: 0.6194 - val_accuracy: 0.8010\n",
      "Epoch 127/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3116 - accuracy: 0.8927 - val_loss: 0.6193 - val_accuracy: 0.8020\n",
      "Epoch 128/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3104 - accuracy: 0.8932 - val_loss: 0.6205 - val_accuracy: 0.8000\n",
      "Epoch 129/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3095 - accuracy: 0.8930 - val_loss: 0.6214 - val_accuracy: 0.8000\n",
      "Epoch 130/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3083 - accuracy: 0.8937 - val_loss: 0.6263 - val_accuracy: 0.8040\n",
      "Epoch 131/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.3072 - accuracy: 0.8943 - val_loss: 0.6246 - val_accuracy: 0.7990\n",
      "Epoch 132/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3062 - accuracy: 0.8942 - val_loss: 0.6326 - val_accuracy: 0.8030\n",
      "Epoch 133/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3056 - accuracy: 0.8948 - val_loss: 0.6304 - val_accuracy: 0.8060\n",
      "Epoch 134/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.3041 - accuracy: 0.8960 - val_loss: 0.6290 - val_accuracy: 0.8060\n",
      "Epoch 135/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3033 - accuracy: 0.8955 - val_loss: 0.6297 - val_accuracy: 0.8030\n",
      "Epoch 136/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3021 - accuracy: 0.8968 - val_loss: 0.6290 - val_accuracy: 0.7950\n",
      "Epoch 137/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3011 - accuracy: 0.8980 - val_loss: 0.6353 - val_accuracy: 0.7970\n",
      "Epoch 138/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.3002 - accuracy: 0.8969 - val_loss: 0.6351 - val_accuracy: 0.8030\n",
      "Epoch 139/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.2991 - accuracy: 0.8974 - val_loss: 0.6281 - val_accuracy: 0.8040\n",
      "Epoch 140/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.2979 - accuracy: 0.8987 - val_loss: 0.6296 - val_accuracy: 0.7970\n",
      "Epoch 141/150\n",
      "225/225 [==============================] - 1s 7ms/step - loss: 0.2970 - accuracy: 0.8998 - val_loss: 0.6333 - val_accuracy: 0.7970\n",
      "Epoch 142/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.2961 - accuracy: 0.8984 - val_loss: 0.6386 - val_accuracy: 0.7980\n",
      "Epoch 143/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.2951 - accuracy: 0.8998 - val_loss: 0.6385 - val_accuracy: 0.7980\n",
      "Epoch 144/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.2943 - accuracy: 0.9001 - val_loss: 0.6394 - val_accuracy: 0.8010\n",
      "Epoch 145/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.2928 - accuracy: 0.8997 - val_loss: 0.6586 - val_accuracy: 0.7980\n",
      "Epoch 146/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.2915 - accuracy: 0.9014 - val_loss: 0.6519 - val_accuracy: 0.8050\n",
      "Epoch 147/150\n",
      "225/225 [==============================] - 1s 7ms/step - loss: 0.2905 - accuracy: 0.9015 - val_loss: 0.6446 - val_accuracy: 0.8000\n",
      "Epoch 148/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.2894 - accuracy: 0.9013 - val_loss: 0.6457 - val_accuracy: 0.7940\n",
      "Epoch 149/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.2888 - accuracy: 0.9027 - val_loss: 0.6465 - val_accuracy: 0.7940\n",
      "Epoch 150/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.2874 - accuracy: 0.9033 - val_loss: 0.6531 - val_accuracy: 0.7960\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "baseline_model_val = baseline_model.fit(X_train_tokens, y_train_lb,\n",
    "                                        epochs=150, batch_size=256,\n",
    "                                        validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance\n",
    "\n",
    "The attribute `.history` (stored as a dictionary) contains four entries now: one per metric that was being monitored during training and validation. Print the keys of this dictionary for confirmation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "baseline_model_val_dict = baseline_model_val.history\n",
    "\n",
    "# Print the keys\n",
    "baseline_model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the training data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9032521843910217"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model_val_dict['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Training Loss: 1.5 \n",
      "Training Accuracy: 0.903\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model_val_dict['loss'][1], baseline_model_val_dict['accuracy'][-1]\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate this model on the test data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "Test Loss: 1.32 \n",
      "Test Accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model_val_dict['val_loss'][1], baseline_model_val_dict['val_accuracy'][-1]\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Results \n",
    "\n",
    "Plot the loss versus the number of epochs. Be sure to include the training and the validation loss in the same plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['loss'], label='Training')\n",
    "    plt.plot(history['val_loss'], label='Validation')\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['accuracy'], label='Training')\n",
    "    plt.plot(history['val_accuracy'], label='Validation')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy\")\n",
    "    \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss vs number of epochs with train and validation sets\n",
    "# Accuracy vs number of epochs with train and validation sets\n",
    "visualize_training_results(baseline_model_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a second plot comparing training and validation accuracy to the number of epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice an interesting pattern here? Although the training accuracy keeps increasing when going through more epochs, and the training loss keeps decreasing, the validation accuracy and loss don't necessarily do the same. After a certain point, validation accuracy keeps swinging, which means that you're probably **overfitting** the model to the training data when you train for many epochs past a certain dropoff point. Let's tackle this now. You will now specify an early stopping point when training your model. \n",
    "\n",
    "\n",
    "## Early Stopping\n",
    "\n",
    "Overfitting neural networks is something you **_want_** to avoid at all costs. However, it's not possible to know in advance how many *epochs* you need to train your model on, and running the model multiple times with varying number of *epochs* maybe helpful, but is a time-consuming process. \n",
    "\n",
    "We've defined a model with the same architecture as above. This time specify an early stopping point when training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "model_2.add(layers.Dense(25, activation='relu'))\n",
    "model_2.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='SGD', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import `EarlyStopping` and `ModelCheckpoint` from `keras.callbacks` \n",
    "- Define a list, `early_stopping`: \n",
    "  - Monitor `'val_loss'` and continue training for 10 epochs before stopping \n",
    "  - Save the best model while monitoring `'val_loss'` \n",
    " \n",
    "> If you need help, consult [documentation](https://keras.io/callbacks/).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "checkpoint_filepath = 'best_model.h5'\n",
    "early_stopping = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10),\n",
    "    ModelCheckpoint(filepath=checkpoint_filepath,\n",
    "                    monitor='val_loss',\n",
    "                    save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `model_2`. Make sure you set the `callbacks` argument to `early_stopping`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.8977 - acc: 0.2542 - val_loss: 1.8360 - val_acc: 0.3110\n",
      "Epoch 2/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.6909 - acc: 0.4063 - val_loss: 1.5736 - val_acc: 0.4380\n",
      "Epoch 3/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.3982 - acc: 0.5435 - val_loss: 1.2659 - val_acc: 0.5940\n",
      "Epoch 4/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.1206 - acc: 0.6420 - val_loss: 1.0200 - val_acc: 0.6680\n",
      "Epoch 5/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9262 - acc: 0.6924 - val_loss: 0.8726 - val_acc: 0.6830\n",
      "Epoch 6/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8089 - acc: 0.7167 - val_loss: 0.7877 - val_acc: 0.7040\n",
      "Epoch 7/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7382 - acc: 0.7325 - val_loss: 0.7352 - val_acc: 0.7130\n",
      "Epoch 8/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6926 - acc: 0.7435 - val_loss: 0.7008 - val_acc: 0.7330\n",
      "Epoch 9/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6602 - acc: 0.7521 - val_loss: 0.6803 - val_acc: 0.7360\n",
      "Epoch 10/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6356 - acc: 0.7594 - val_loss: 0.6579 - val_acc: 0.7430\n",
      "Epoch 11/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6160 - acc: 0.7677 - val_loss: 0.6430 - val_acc: 0.7490\n",
      "Epoch 12/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5994 - acc: 0.7730 - val_loss: 0.6293 - val_acc: 0.7600\n",
      "Epoch 13/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5857 - acc: 0.7782 - val_loss: 0.6193 - val_acc: 0.7630\n",
      "Epoch 14/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5732 - acc: 0.7828 - val_loss: 0.6114 - val_acc: 0.7670\n",
      "Epoch 15/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5625 - acc: 0.7874 - val_loss: 0.6065 - val_acc: 0.7660\n",
      "Epoch 16/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5526 - acc: 0.7915 - val_loss: 0.5959 - val_acc: 0.7660\n",
      "Epoch 17/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5438 - acc: 0.7960 - val_loss: 0.5914 - val_acc: 0.7690\n",
      "Epoch 18/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5357 - acc: 0.7988 - val_loss: 0.5879 - val_acc: 0.7720\n",
      "Epoch 19/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5280 - acc: 0.8031 - val_loss: 0.5811 - val_acc: 0.7760\n",
      "Epoch 20/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5208 - acc: 0.8068 - val_loss: 0.5782 - val_acc: 0.7770\n",
      "Epoch 21/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5144 - acc: 0.8098 - val_loss: 0.5768 - val_acc: 0.7730\n",
      "Epoch 22/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5078 - acc: 0.8128 - val_loss: 0.5700 - val_acc: 0.7920\n",
      "Epoch 23/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5020 - acc: 0.8151 - val_loss: 0.5691 - val_acc: 0.7900\n",
      "Epoch 24/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4962 - acc: 0.8179 - val_loss: 0.5656 - val_acc: 0.7900\n",
      "Epoch 25/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4907 - acc: 0.8208 - val_loss: 0.5633 - val_acc: 0.7970\n",
      "Epoch 26/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4856 - acc: 0.8218 - val_loss: 0.5674 - val_acc: 0.7930\n",
      "Epoch 27/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4809 - acc: 0.8236 - val_loss: 0.5604 - val_acc: 0.7940\n",
      "Epoch 28/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4763 - acc: 0.8268 - val_loss: 0.5615 - val_acc: 0.8000\n",
      "Epoch 29/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4719 - acc: 0.8287 - val_loss: 0.5600 - val_acc: 0.8010\n",
      "Epoch 30/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4679 - acc: 0.8300 - val_loss: 0.5589 - val_acc: 0.8020\n",
      "Epoch 31/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4636 - acc: 0.8316 - val_loss: 0.5585 - val_acc: 0.7950\n",
      "Epoch 32/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4600 - acc: 0.8335 - val_loss: 0.5569 - val_acc: 0.8080\n",
      "Epoch 33/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4560 - acc: 0.8355 - val_loss: 0.5561 - val_acc: 0.8030\n",
      "Epoch 34/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4527 - acc: 0.8365 - val_loss: 0.5532 - val_acc: 0.8090\n",
      "Epoch 35/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4493 - acc: 0.8379 - val_loss: 0.5516 - val_acc: 0.8070\n",
      "Epoch 36/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4461 - acc: 0.8386 - val_loss: 0.5528 - val_acc: 0.8050\n",
      "Epoch 37/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4433 - acc: 0.8405 - val_loss: 0.5547 - val_acc: 0.8130\n",
      "Epoch 38/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4399 - acc: 0.8414 - val_loss: 0.5565 - val_acc: 0.8110\n",
      "Epoch 39/150\n",
      "225/225 [==============================] - 4s 19ms/step - loss: 0.4369 - acc: 0.8430 - val_loss: 0.5510 - val_acc: 0.8200\n",
      "Epoch 40/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4341 - acc: 0.8445 - val_loss: 0.5516 - val_acc: 0.8110\n",
      "Epoch 41/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4316 - acc: 0.8452 - val_loss: 0.5562 - val_acc: 0.8060\n",
      "Epoch 42/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4289 - acc: 0.8464 - val_loss: 0.5564 - val_acc: 0.8080\n",
      "Epoch 43/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4265 - acc: 0.8471 - val_loss: 0.5526 - val_acc: 0.8110\n",
      "Epoch 44/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4239 - acc: 0.8493 - val_loss: 0.5512 - val_acc: 0.8100\n",
      "Epoch 45/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4215 - acc: 0.8491 - val_loss: 0.5522 - val_acc: 0.8110\n",
      "Epoch 46/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4192 - acc: 0.8502 - val_loss: 0.5519 - val_acc: 0.8110\n",
      "Epoch 47/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4170 - acc: 0.8516 - val_loss: 0.5547 - val_acc: 0.8070\n",
      "Epoch 48/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4147 - acc: 0.8519 - val_loss: 0.5536 - val_acc: 0.8170\n",
      "Epoch 49/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.4128 - acc: 0.8530 - val_loss: 0.5531 - val_acc: 0.8150\n"
     ]
    }
   ],
   "source": [
    "model_2_val = model_2.fit(X_train_tokens, y_train_lb,\n",
    "                          epochs=150, batch_size=256,\n",
    "                          callbacks=early_stopping,\n",
    "                          validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best (saved) model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best (saved) model\n",
    "from keras.models import load_model\n",
    "saved_model = load_model(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use this model to to calculate the training and test accuracy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797/1797 [==============================] - 2s 1ms/step - loss: 0.4319 - acc: 0.8458\n",
      "Training Loss: 0.432 \n",
      "Training Accuracy: 0.846\n",
      "----------\n",
      "47/47 [==============================] - 0s 1ms/step - loss: 0.5380 - acc: 0.7893\n",
      "Test Loss: 0.538 \n",
      "Test Accuracy: 0.789\n"
     ]
    }
   ],
   "source": [
    "results_train = saved_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = saved_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.5510 - acc: 0.8200\n",
      "Test Loss: 0.551 \n",
      "Test Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "results_val = saved_model.evaluate(X_val_tokens, y_val_lb)\n",
    "print(f'Test Loss: {results_val[0]:.3} \\nTest Accuracy: {results_val[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicely done! Did you notice that the model didn't train for all 150 epochs? You reduced your training time. \n",
    "\n",
    "Now, take a look at how regularization techniques can further improve your model performance. \n",
    "\n",
    "## L2 Regularization \n",
    "\n",
    "First, take a look at L2 regularization. Keras makes L2 regularization easy. Simply add the `kernel_regularizer=keras.regularizers.l2(lambda_coeff)` parameter to any model layer. The `lambda_coeff` parameter determines the strength of the regularization you wish to perform. \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L2 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 2.5197 - acc: 0.2396 - val_loss: 2.4053 - val_acc: 0.3150\n",
      "Epoch 2/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 2.2123 - acc: 0.4339 - val_loss: 2.0390 - val_acc: 0.5000\n",
      "Epoch 3/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.8721 - acc: 0.5865 - val_loss: 1.7589 - val_acc: 0.6210\n",
      "Epoch 4/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.6411 - acc: 0.6610 - val_loss: 1.5786 - val_acc: 0.6620\n",
      "Epoch 5/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.4901 - acc: 0.7011 - val_loss: 1.4592 - val_acc: 0.6850\n",
      "Epoch 6/150\n",
      "225/225 [==============================] - 1s 7ms/step - loss: 1.3829 - acc: 0.7255 - val_loss: 1.3721 - val_acc: 0.7030\n",
      "Epoch 7/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.3033 - acc: 0.7429 - val_loss: 1.3061 - val_acc: 0.7160\n",
      "Epoch 8/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.2426 - acc: 0.7554 - val_loss: 1.2593 - val_acc: 0.7150\n",
      "Epoch 9/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.1943 - acc: 0.7645 - val_loss: 1.2178 - val_acc: 0.7340\n",
      "Epoch 10/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.1543 - acc: 0.7713 - val_loss: 1.1849 - val_acc: 0.7410\n",
      "Epoch 11/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.1197 - acc: 0.7769 - val_loss: 1.1525 - val_acc: 0.7490\n",
      "Epoch 12/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0892 - acc: 0.7822 - val_loss: 1.1286 - val_acc: 0.7560\n",
      "Epoch 13/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0616 - acc: 0.7869 - val_loss: 1.1045 - val_acc: 0.7560\n",
      "Epoch 14/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0364 - acc: 0.7908 - val_loss: 1.0812 - val_acc: 0.7570\n",
      "Epoch 15/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0130 - acc: 0.7944 - val_loss: 1.0601 - val_acc: 0.7620\n",
      "Epoch 16/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9912 - acc: 0.7988 - val_loss: 1.0405 - val_acc: 0.7640\n",
      "Epoch 17/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9709 - acc: 0.8016 - val_loss: 1.0260 - val_acc: 0.7710\n",
      "Epoch 18/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9521 - acc: 0.8046 - val_loss: 1.0069 - val_acc: 0.7670\n",
      "Epoch 19/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9338 - acc: 0.8073 - val_loss: 0.9924 - val_acc: 0.7780\n",
      "Epoch 20/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9168 - acc: 0.8099 - val_loss: 0.9755 - val_acc: 0.7760\n",
      "Epoch 21/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9008 - acc: 0.8127 - val_loss: 0.9592 - val_acc: 0.7780\n",
      "Epoch 22/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8856 - acc: 0.8145 - val_loss: 0.9462 - val_acc: 0.7810\n",
      "Epoch 23/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8711 - acc: 0.8161 - val_loss: 0.9329 - val_acc: 0.7890\n",
      "Epoch 24/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8574 - acc: 0.8183 - val_loss: 0.9215 - val_acc: 0.7930\n",
      "Epoch 25/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8442 - acc: 0.8203 - val_loss: 0.9089 - val_acc: 0.7930\n",
      "Epoch 26/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8317 - acc: 0.8221 - val_loss: 0.8978 - val_acc: 0.7970\n",
      "Epoch 27/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8199 - acc: 0.8238 - val_loss: 0.8882 - val_acc: 0.7940\n",
      "Epoch 28/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8087 - acc: 0.8259 - val_loss: 0.8788 - val_acc: 0.7980\n",
      "Epoch 29/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7977 - acc: 0.8270 - val_loss: 0.8695 - val_acc: 0.7940\n",
      "Epoch 30/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7876 - acc: 0.8282 - val_loss: 0.8618 - val_acc: 0.7970\n",
      "Epoch 31/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.7776 - acc: 0.8296 - val_loss: 0.8512 - val_acc: 0.8020\n",
      "Epoch 32/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7682 - acc: 0.8309 - val_loss: 0.8451 - val_acc: 0.8030\n",
      "Epoch 33/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7592 - acc: 0.8316 - val_loss: 0.8399 - val_acc: 0.8030\n",
      "Epoch 34/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7506 - acc: 0.8332 - val_loss: 0.8294 - val_acc: 0.7980\n",
      "Epoch 35/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7426 - acc: 0.8337 - val_loss: 0.8234 - val_acc: 0.8000\n",
      "Epoch 36/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7347 - acc: 0.8347 - val_loss: 0.8169 - val_acc: 0.7990\n",
      "Epoch 37/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7270 - acc: 0.8365 - val_loss: 0.8089 - val_acc: 0.8050\n",
      "Epoch 38/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7201 - acc: 0.8365 - val_loss: 0.8040 - val_acc: 0.8080\n",
      "Epoch 39/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7130 - acc: 0.8372 - val_loss: 0.7997 - val_acc: 0.8030\n",
      "Epoch 40/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7065 - acc: 0.8384 - val_loss: 0.7949 - val_acc: 0.8030\n",
      "Epoch 41/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.7001 - acc: 0.8394 - val_loss: 0.7863 - val_acc: 0.8070\n",
      "Epoch 42/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6942 - acc: 0.8404 - val_loss: 0.7861 - val_acc: 0.7960\n",
      "Epoch 43/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6883 - acc: 0.8415 - val_loss: 0.7771 - val_acc: 0.8090\n",
      "Epoch 44/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.6826 - acc: 0.8415 - val_loss: 0.7716 - val_acc: 0.8040\n",
      "Epoch 45/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6773 - acc: 0.8428 - val_loss: 0.7721 - val_acc: 0.8080\n",
      "Epoch 46/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6725 - acc: 0.8433 - val_loss: 0.7636 - val_acc: 0.8040\n",
      "Epoch 47/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6673 - acc: 0.8436 - val_loss: 0.7600 - val_acc: 0.8040\n",
      "Epoch 48/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6627 - acc: 0.8445 - val_loss: 0.7580 - val_acc: 0.8070\n",
      "Epoch 49/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6581 - acc: 0.8455 - val_loss: 0.7534 - val_acc: 0.8080\n",
      "Epoch 50/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.6538 - acc: 0.8454 - val_loss: 0.7499 - val_acc: 0.8080\n",
      "Epoch 51/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6497 - acc: 0.8454 - val_loss: 0.7474 - val_acc: 0.8050\n",
      "Epoch 52/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.6458 - acc: 0.8464 - val_loss: 0.7416 - val_acc: 0.8110\n",
      "Epoch 53/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.6418 - acc: 0.8475 - val_loss: 0.7398 - val_acc: 0.8130\n",
      "Epoch 54/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.6380 - acc: 0.8468 - val_loss: 0.7357 - val_acc: 0.8160\n",
      "Epoch 55/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.6346 - acc: 0.8486 - val_loss: 0.7361 - val_acc: 0.8090\n",
      "Epoch 56/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.6311 - acc: 0.8485 - val_loss: 0.7304 - val_acc: 0.8120\n",
      "Epoch 57/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6279 - acc: 0.8493 - val_loss: 0.7266 - val_acc: 0.8080\n",
      "Epoch 58/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6246 - acc: 0.8489 - val_loss: 0.7279 - val_acc: 0.8070\n",
      "Epoch 59/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.6215 - acc: 0.8502 - val_loss: 0.7261 - val_acc: 0.8090\n",
      "Epoch 60/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6186 - acc: 0.8502 - val_loss: 0.7184 - val_acc: 0.8080\n",
      "Epoch 61/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.6154 - acc: 0.8509 - val_loss: 0.7192 - val_acc: 0.8070\n",
      "Epoch 62/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6130 - acc: 0.8504 - val_loss: 0.7189 - val_acc: 0.8140\n",
      "Epoch 63/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6102 - acc: 0.8503 - val_loss: 0.7171 - val_acc: 0.8080\n",
      "Epoch 64/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6077 - acc: 0.8519 - val_loss: 0.7139 - val_acc: 0.8140\n",
      "Epoch 65/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6052 - acc: 0.8519 - val_loss: 0.7163 - val_acc: 0.8100\n",
      "Epoch 66/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6029 - acc: 0.8523 - val_loss: 0.7120 - val_acc: 0.8100\n",
      "Epoch 67/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.6007 - acc: 0.8516 - val_loss: 0.7135 - val_acc: 0.8010\n",
      "Epoch 68/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5985 - acc: 0.8523 - val_loss: 0.7052 - val_acc: 0.8050\n",
      "Epoch 69/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5964 - acc: 0.8535 - val_loss: 0.7045 - val_acc: 0.8100\n",
      "Epoch 70/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5943 - acc: 0.8535 - val_loss: 0.7044 - val_acc: 0.8040\n",
      "Epoch 71/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5925 - acc: 0.8540 - val_loss: 0.7005 - val_acc: 0.8070\n",
      "Epoch 72/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5903 - acc: 0.8545 - val_loss: 0.7000 - val_acc: 0.8120\n",
      "Epoch 73/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5884 - acc: 0.8540 - val_loss: 0.6992 - val_acc: 0.8070\n",
      "Epoch 74/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5868 - acc: 0.8553 - val_loss: 0.6969 - val_acc: 0.8060\n",
      "Epoch 75/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5848 - acc: 0.8543 - val_loss: 0.6982 - val_acc: 0.8060\n",
      "Epoch 76/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5834 - acc: 0.8551 - val_loss: 0.6974 - val_acc: 0.8160\n",
      "Epoch 77/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5816 - acc: 0.8555 - val_loss: 0.6933 - val_acc: 0.8110\n",
      "Epoch 78/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5799 - acc: 0.8550 - val_loss: 0.6953 - val_acc: 0.8140\n",
      "Epoch 79/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5783 - acc: 0.8554 - val_loss: 0.7025 - val_acc: 0.8060\n",
      "Epoch 80/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5771 - acc: 0.8558 - val_loss: 0.6935 - val_acc: 0.8070\n",
      "Epoch 81/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5755 - acc: 0.8553 - val_loss: 0.6967 - val_acc: 0.8090\n",
      "Epoch 82/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5741 - acc: 0.8561 - val_loss: 0.6865 - val_acc: 0.8090\n",
      "Epoch 83/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5728 - acc: 0.8561 - val_loss: 0.6851 - val_acc: 0.8070\n",
      "Epoch 84/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5712 - acc: 0.8563 - val_loss: 0.6856 - val_acc: 0.8110\n",
      "Epoch 85/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5701 - acc: 0.8569 - val_loss: 0.6868 - val_acc: 0.8130\n",
      "Epoch 86/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5691 - acc: 0.8566 - val_loss: 0.6825 - val_acc: 0.8130\n",
      "Epoch 87/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5676 - acc: 0.8567 - val_loss: 0.6835 - val_acc: 0.8050\n",
      "Epoch 88/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5664 - acc: 0.8566 - val_loss: 0.6848 - val_acc: 0.8060\n",
      "Epoch 89/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.5654 - acc: 0.8571 - val_loss: 0.6853 - val_acc: 0.8050\n",
      "Epoch 90/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5643 - acc: 0.8576 - val_loss: 0.6808 - val_acc: 0.8130\n",
      "Epoch 91/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5630 - acc: 0.8568 - val_loss: 0.6813 - val_acc: 0.8140\n",
      "Epoch 92/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5618 - acc: 0.8575 - val_loss: 0.6797 - val_acc: 0.8030\n",
      "Epoch 93/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5608 - acc: 0.8583 - val_loss: 0.6774 - val_acc: 0.8110\n",
      "Epoch 94/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5601 - acc: 0.8586 - val_loss: 0.6808 - val_acc: 0.8100\n",
      "Epoch 95/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5592 - acc: 0.8582 - val_loss: 0.6805 - val_acc: 0.8090\n",
      "Epoch 96/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5581 - acc: 0.8588 - val_loss: 0.6789 - val_acc: 0.8140\n",
      "Epoch 97/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5572 - acc: 0.8584 - val_loss: 0.6784 - val_acc: 0.8060\n",
      "Epoch 98/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5561 - acc: 0.8589 - val_loss: 0.6781 - val_acc: 0.8060\n",
      "Epoch 99/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5552 - acc: 0.8587 - val_loss: 0.6817 - val_acc: 0.8160\n",
      "Epoch 100/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5547 - acc: 0.8579 - val_loss: 0.6755 - val_acc: 0.8070\n",
      "Epoch 101/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5536 - acc: 0.8588 - val_loss: 0.6794 - val_acc: 0.8110\n",
      "Epoch 102/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5528 - acc: 0.8592 - val_loss: 0.6776 - val_acc: 0.8130\n",
      "Epoch 103/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5520 - acc: 0.8584 - val_loss: 0.6737 - val_acc: 0.8010\n",
      "Epoch 104/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5511 - acc: 0.8587 - val_loss: 0.6757 - val_acc: 0.8090\n",
      "Epoch 105/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5506 - acc: 0.8589 - val_loss: 0.6741 - val_acc: 0.8050\n",
      "Epoch 106/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5497 - acc: 0.8592 - val_loss: 0.6760 - val_acc: 0.8080\n",
      "Epoch 107/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5488 - acc: 0.8595 - val_loss: 0.6765 - val_acc: 0.8120\n",
      "Epoch 108/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5481 - acc: 0.8587 - val_loss: 0.6704 - val_acc: 0.8020\n",
      "Epoch 109/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.5472 - acc: 0.8600 - val_loss: 0.6772 - val_acc: 0.8110\n",
      "Epoch 110/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5469 - acc: 0.8601 - val_loss: 0.6732 - val_acc: 0.8120\n",
      "Epoch 111/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5458 - acc: 0.8599 - val_loss: 0.6723 - val_acc: 0.8090\n",
      "Epoch 112/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5455 - acc: 0.8592 - val_loss: 0.6735 - val_acc: 0.8090\n",
      "Epoch 113/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5447 - acc: 0.8601 - val_loss: 0.6729 - val_acc: 0.8050\n",
      "Epoch 114/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5441 - acc: 0.8601 - val_loss: 0.6703 - val_acc: 0.8030\n",
      "Epoch 115/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5434 - acc: 0.8603 - val_loss: 0.6792 - val_acc: 0.8070\n",
      "Epoch 116/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5425 - acc: 0.8603 - val_loss: 0.6702 - val_acc: 0.8090\n",
      "Epoch 117/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5424 - acc: 0.8604 - val_loss: 0.6697 - val_acc: 0.8080\n",
      "Epoch 118/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5416 - acc: 0.8601 - val_loss: 0.6737 - val_acc: 0.8050\n",
      "Epoch 119/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5409 - acc: 0.8605 - val_loss: 0.6691 - val_acc: 0.8060\n",
      "Epoch 120/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5404 - acc: 0.8610 - val_loss: 0.6775 - val_acc: 0.8050\n",
      "Epoch 121/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5397 - acc: 0.8606 - val_loss: 0.6744 - val_acc: 0.8010\n",
      "Epoch 122/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5390 - acc: 0.8607 - val_loss: 0.6724 - val_acc: 0.8090\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5389 - acc: 0.8607 - val_loss: 0.6715 - val_acc: 0.8090\n",
      "Epoch 124/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5379 - acc: 0.8608 - val_loss: 0.6712 - val_acc: 0.8050\n",
      "Epoch 125/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5377 - acc: 0.8609 - val_loss: 0.6642 - val_acc: 0.8080\n",
      "Epoch 126/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5373 - acc: 0.8605 - val_loss: 0.6656 - val_acc: 0.8000\n",
      "Epoch 127/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5367 - acc: 0.8608 - val_loss: 0.6690 - val_acc: 0.8110\n",
      "Epoch 128/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5361 - acc: 0.8615 - val_loss: 0.6703 - val_acc: 0.8020\n",
      "Epoch 129/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5355 - acc: 0.8609 - val_loss: 0.6706 - val_acc: 0.8070\n",
      "Epoch 130/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5350 - acc: 0.8615 - val_loss: 0.6738 - val_acc: 0.8010\n",
      "Epoch 131/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5346 - acc: 0.8617 - val_loss: 0.6667 - val_acc: 0.8060\n",
      "Epoch 132/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5339 - acc: 0.8615 - val_loss: 0.6642 - val_acc: 0.8070\n",
      "Epoch 133/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5337 - acc: 0.8613 - val_loss: 0.6662 - val_acc: 0.8070\n",
      "Epoch 134/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5332 - acc: 0.8622 - val_loss: 0.6693 - val_acc: 0.8060\n",
      "Epoch 135/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5328 - acc: 0.8618 - val_loss: 0.6689 - val_acc: 0.8100\n",
      "Epoch 136/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5321 - acc: 0.8615 - val_loss: 0.6612 - val_acc: 0.8010\n",
      "Epoch 137/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5317 - acc: 0.8613 - val_loss: 0.6658 - val_acc: 0.8120\n",
      "Epoch 138/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5311 - acc: 0.8620 - val_loss: 0.6669 - val_acc: 0.8010\n",
      "Epoch 139/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5308 - acc: 0.8619 - val_loss: 0.6628 - val_acc: 0.7940\n",
      "Epoch 140/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5302 - acc: 0.8624 - val_loss: 0.6667 - val_acc: 0.8100\n",
      "Epoch 141/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5299 - acc: 0.8614 - val_loss: 0.6665 - val_acc: 0.8030\n",
      "Epoch 142/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5293 - acc: 0.8628 - val_loss: 0.6609 - val_acc: 0.7980\n",
      "Epoch 143/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5292 - acc: 0.8620 - val_loss: 0.6604 - val_acc: 0.8030\n",
      "Epoch 144/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5287 - acc: 0.8623 - val_loss: 0.6603 - val_acc: 0.8090\n",
      "Epoch 145/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5282 - acc: 0.8621 - val_loss: 0.6629 - val_acc: 0.8070\n",
      "Epoch 146/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5278 - acc: 0.8624 - val_loss: 0.6642 - val_acc: 0.8020\n",
      "Epoch 147/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5274 - acc: 0.8623 - val_loss: 0.6619 - val_acc: 0.8050\n",
      "Epoch 148/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5270 - acc: 0.8626 - val_loss: 0.6595 - val_acc: 0.8030\n",
      "Epoch 149/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5266 - acc: 0.8623 - val_loss: 0.6660 - val_acc: 0.8060\n",
      "Epoch 150/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.5261 - acc: 0.8617 - val_loss: 0.6602 - val_acc: 0.8040\n"
     ]
    }
   ],
   "source": [
    "# Import regularizers\n",
    "from keras import regularizers\n",
    "\n",
    "lambda_coeff = 0.005\n",
    "\n",
    "random.seed(123)\n",
    "L2_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L2_model.add(layers.Dense(50, activation='relu', \n",
    "                          input_shape=(2000,),\n",
    "                          kernel_regularizer=regularizers.L2(lambda_coeff)))\n",
    "\n",
    "# Add another hidden layer\n",
    "L2_model.add(layers.Dense(25, activation='relu',\n",
    "                          kernel_regularizer=regularizers.L2(lambda_coeff)))\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['acc'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at the training as well as the validation accuracy for both the L2 and the baseline models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['acc'] \n",
    "L2_val_acc_values = L2_model_dict['val_acc']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['accuracy'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_accuracy']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "epochs = range(1, len(L2_acc_values) + 1)\n",
    "ax.plot(epochs, L2_acc_values, label='Training acc L2')\n",
    "ax.plot(epochs, L2_val_acc_values, label='Validation acc L2')\n",
    "ax.plot(epochs, baseline_model_acc, label='Training acc')\n",
    "ax.plot(epochs, baseline_model_val_acc, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of L2 regularization are quite disappointing here. Notice the discrepancy between validation and training accuracy seems to have decreased slightly, but the end result is definitely not getting better.  \n",
    "\n",
    "\n",
    "## L1 Regularization\n",
    "\n",
    "Now have a look at L1 regularization. Will this work better? \n",
    "\n",
    "- Use 2 hidden layers with 50 units in the first and 25 in the second layer, both with `'relu'` activation functions \n",
    "- Add L1 regularization to both the hidden layers with 0.005 as the `lambda_coeff` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 13.6952 - acc: 0.2134 - val_loss: 11.1794 - val_acc: 0.2510\n",
      "Epoch 2/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 9.0357 - acc: 0.3753 - val_loss: 7.0891 - val_acc: 0.4670\n",
      "Epoch 3/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 5.5583 - acc: 0.5669 - val_loss: 4.2498 - val_acc: 0.6100\n",
      "Epoch 4/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 3.3368 - acc: 0.6538 - val_loss: 2.6502 - val_acc: 0.6450\n",
      "Epoch 5/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 2.2997 - acc: 0.6744 - val_loss: 2.1266 - val_acc: 0.6600\n",
      "Epoch 6/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 2.0237 - acc: 0.6809 - val_loss: 1.9695 - val_acc: 0.6710\n",
      "Epoch 7/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.8918 - acc: 0.6871 - val_loss: 1.8577 - val_acc: 0.6840\n",
      "Epoch 8/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.7927 - acc: 0.6924 - val_loss: 1.7722 - val_acc: 0.6830\n",
      "Epoch 9/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.7132 - acc: 0.6965 - val_loss: 1.6996 - val_acc: 0.6950\n",
      "Epoch 10/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.6463 - acc: 0.7000 - val_loss: 1.6356 - val_acc: 0.6930\n",
      "Epoch 11/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.5876 - acc: 0.7028 - val_loss: 1.5803 - val_acc: 0.6880\n",
      "Epoch 12/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.5350 - acc: 0.7054 - val_loss: 1.5322 - val_acc: 0.6910\n",
      "Epoch 13/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.4870 - acc: 0.7088 - val_loss: 1.4828 - val_acc: 0.6930\n",
      "Epoch 14/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.4420 - acc: 0.7119 - val_loss: 1.4408 - val_acc: 0.6960\n",
      "Epoch 15/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.4007 - acc: 0.7138 - val_loss: 1.3983 - val_acc: 0.7020\n",
      "Epoch 16/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.3622 - acc: 0.7166 - val_loss: 1.3643 - val_acc: 0.7050\n",
      "Epoch 17/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.3265 - acc: 0.7185 - val_loss: 1.3276 - val_acc: 0.7120\n",
      "Epoch 18/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.2936 - acc: 0.7205 - val_loss: 1.2990 - val_acc: 0.7140\n",
      "Epoch 19/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.2630 - acc: 0.7226 - val_loss: 1.2666 - val_acc: 0.7140\n",
      "Epoch 20/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.2358 - acc: 0.7239 - val_loss: 1.2383 - val_acc: 0.7150\n",
      "Epoch 21/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.2107 - acc: 0.7259 - val_loss: 1.2165 - val_acc: 0.7170\n",
      "Epoch 22/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.1884 - acc: 0.7279 - val_loss: 1.1957 - val_acc: 0.7210\n",
      "Epoch 23/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.1678 - acc: 0.7302 - val_loss: 1.1791 - val_acc: 0.7150\n",
      "Epoch 24/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.1499 - acc: 0.7315 - val_loss: 1.1590 - val_acc: 0.7200\n",
      "Epoch 25/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.1336 - acc: 0.7335 - val_loss: 1.1470 - val_acc: 0.7190\n",
      "Epoch 26/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.1194 - acc: 0.7351 - val_loss: 1.1315 - val_acc: 0.7260\n",
      "Epoch 27/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.1064 - acc: 0.7359 - val_loss: 1.1188 - val_acc: 0.7220\n",
      "Epoch 28/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0946 - acc: 0.7368 - val_loss: 1.1078 - val_acc: 0.7260\n",
      "Epoch 29/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0836 - acc: 0.7382 - val_loss: 1.0993 - val_acc: 0.7230\n",
      "Epoch 30/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0730 - acc: 0.7398 - val_loss: 1.0899 - val_acc: 0.7270\n",
      "Epoch 31/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0633 - acc: 0.7405 - val_loss: 1.0806 - val_acc: 0.7240\n",
      "Epoch 32/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0540 - acc: 0.7420 - val_loss: 1.0756 - val_acc: 0.7210\n",
      "Epoch 33/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0454 - acc: 0.7422 - val_loss: 1.0713 - val_acc: 0.7270\n",
      "Epoch 34/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0371 - acc: 0.7437 - val_loss: 1.0562 - val_acc: 0.7260\n",
      "Epoch 35/150\n",
      "225/225 [==============================] - 1s 7ms/step - loss: 1.0300 - acc: 0.7449 - val_loss: 1.0502 - val_acc: 0.7280\n",
      "Epoch 36/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.0232 - acc: 0.7444 - val_loss: 1.0453 - val_acc: 0.7260\n",
      "Epoch 37/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 1.0167 - acc: 0.7456 - val_loss: 1.0375 - val_acc: 0.7260\n",
      "Epoch 38/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.0101 - acc: 0.7474 - val_loss: 1.0318 - val_acc: 0.7290\n",
      "Epoch 39/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.0043 - acc: 0.7477 - val_loss: 1.0264 - val_acc: 0.7220\n",
      "Epoch 40/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9986 - acc: 0.7485 - val_loss: 1.0177 - val_acc: 0.7290\n",
      "Epoch 41/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.9931 - acc: 0.7496 - val_loss: 1.0141 - val_acc: 0.7290\n",
      "Epoch 42/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9879 - acc: 0.7500 - val_loss: 1.0095 - val_acc: 0.7310\n",
      "Epoch 43/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9827 - acc: 0.7506 - val_loss: 1.0041 - val_acc: 0.7300\n",
      "Epoch 44/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9780 - acc: 0.7502 - val_loss: 1.0025 - val_acc: 0.7330\n",
      "Epoch 45/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9738 - acc: 0.7516 - val_loss: 1.0003 - val_acc: 0.7310\n",
      "Epoch 46/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9693 - acc: 0.7527 - val_loss: 0.9910 - val_acc: 0.7310\n",
      "Epoch 47/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9656 - acc: 0.7525 - val_loss: 0.9899 - val_acc: 0.7330\n",
      "Epoch 48/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9619 - acc: 0.7529 - val_loss: 0.9865 - val_acc: 0.7310\n",
      "Epoch 49/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9579 - acc: 0.7538 - val_loss: 0.9825 - val_acc: 0.7330\n",
      "Epoch 50/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9546 - acc: 0.7532 - val_loss: 0.9821 - val_acc: 0.7280\n",
      "Epoch 51/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.9512 - acc: 0.7544 - val_loss: 0.9816 - val_acc: 0.7310\n",
      "Epoch 52/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9475 - acc: 0.7550 - val_loss: 0.9751 - val_acc: 0.7330\n",
      "Epoch 53/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9447 - acc: 0.7552 - val_loss: 0.9682 - val_acc: 0.7350\n",
      "Epoch 54/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9414 - acc: 0.7561 - val_loss: 0.9681 - val_acc: 0.7330\n",
      "Epoch 55/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9384 - acc: 0.7562 - val_loss: 0.9649 - val_acc: 0.7350\n",
      "Epoch 56/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9356 - acc: 0.7561 - val_loss: 0.9628 - val_acc: 0.7350\n",
      "Epoch 57/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9331 - acc: 0.7567 - val_loss: 0.9566 - val_acc: 0.7350\n",
      "Epoch 58/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9297 - acc: 0.7578 - val_loss: 0.9644 - val_acc: 0.7390\n",
      "Epoch 59/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9273 - acc: 0.7575 - val_loss: 0.9504 - val_acc: 0.7360\n",
      "Epoch 60/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9248 - acc: 0.7582 - val_loss: 0.9502 - val_acc: 0.7350\n",
      "Epoch 61/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9228 - acc: 0.7574 - val_loss: 0.9531 - val_acc: 0.7360\n",
      "Epoch 62/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9201 - acc: 0.7589 - val_loss: 0.9472 - val_acc: 0.7400\n",
      "Epoch 63/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9176 - acc: 0.7585 - val_loss: 0.9428 - val_acc: 0.7400\n",
      "Epoch 64/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9152 - acc: 0.7591 - val_loss: 0.9396 - val_acc: 0.7420\n",
      "Epoch 65/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9137 - acc: 0.7589 - val_loss: 0.9373 - val_acc: 0.7450\n",
      "Epoch 66/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9115 - acc: 0.7598 - val_loss: 0.9377 - val_acc: 0.7390\n",
      "Epoch 67/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9092 - acc: 0.7593 - val_loss: 0.9345 - val_acc: 0.7410\n",
      "Epoch 68/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9072 - acc: 0.7595 - val_loss: 0.9365 - val_acc: 0.7410\n",
      "Epoch 69/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9051 - acc: 0.7607 - val_loss: 0.9276 - val_acc: 0.7430\n",
      "Epoch 70/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9028 - acc: 0.7613 - val_loss: 0.9396 - val_acc: 0.7430\n",
      "Epoch 71/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.9012 - acc: 0.7607 - val_loss: 0.9346 - val_acc: 0.7410\n",
      "Epoch 72/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8993 - acc: 0.7613 - val_loss: 0.9243 - val_acc: 0.7420\n",
      "Epoch 73/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.8971 - acc: 0.7624 - val_loss: 0.9184 - val_acc: 0.7460\n",
      "Epoch 74/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.8950 - acc: 0.7625 - val_loss: 0.9213 - val_acc: 0.7420\n",
      "Epoch 75/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8930 - acc: 0.7628 - val_loss: 0.9234 - val_acc: 0.7440\n",
      "Epoch 76/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8918 - acc: 0.7626 - val_loss: 0.9282 - val_acc: 0.7400\n",
      "Epoch 77/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8898 - acc: 0.7633 - val_loss: 0.9161 - val_acc: 0.7470\n",
      "Epoch 78/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8875 - acc: 0.7640 - val_loss: 0.9151 - val_acc: 0.7350\n",
      "Epoch 79/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8859 - acc: 0.7637 - val_loss: 0.9103 - val_acc: 0.7490\n",
      "Epoch 80/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8845 - acc: 0.7650 - val_loss: 0.9178 - val_acc: 0.7450\n",
      "Epoch 81/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8825 - acc: 0.7649 - val_loss: 0.9114 - val_acc: 0.7420\n",
      "Epoch 82/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8810 - acc: 0.7639 - val_loss: 0.9130 - val_acc: 0.7460\n",
      "Epoch 83/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8797 - acc: 0.7654 - val_loss: 0.9097 - val_acc: 0.7490\n",
      "Epoch 84/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8783 - acc: 0.7648 - val_loss: 0.9072 - val_acc: 0.7480\n",
      "Epoch 85/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8766 - acc: 0.7651 - val_loss: 0.9051 - val_acc: 0.7480\n",
      "Epoch 86/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8753 - acc: 0.7657 - val_loss: 0.8969 - val_acc: 0.7460\n",
      "Epoch 87/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.8739 - acc: 0.7658 - val_loss: 0.9017 - val_acc: 0.7420\n",
      "Epoch 88/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8728 - acc: 0.7667 - val_loss: 0.9038 - val_acc: 0.7450\n",
      "Epoch 89/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.8710 - acc: 0.7666 - val_loss: 0.9025 - val_acc: 0.7480\n",
      "Epoch 90/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.8703 - acc: 0.7671 - val_loss: 0.8942 - val_acc: 0.7500\n",
      "Epoch 91/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8690 - acc: 0.7681 - val_loss: 0.9035 - val_acc: 0.7460\n",
      "Epoch 92/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8674 - acc: 0.7671 - val_loss: 0.8944 - val_acc: 0.7490\n",
      "Epoch 93/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8664 - acc: 0.7678 - val_loss: 0.9002 - val_acc: 0.7460\n",
      "Epoch 94/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.8653 - acc: 0.7679 - val_loss: 0.8866 - val_acc: 0.7480\n",
      "Epoch 95/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8645 - acc: 0.7689 - val_loss: 0.8889 - val_acc: 0.7490\n",
      "Epoch 96/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8641 - acc: 0.7676 - val_loss: 0.8967 - val_acc: 0.7510\n",
      "Epoch 97/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8623 - acc: 0.7684 - val_loss: 0.8818 - val_acc: 0.7580\n",
      "Epoch 98/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8608 - acc: 0.7695 - val_loss: 0.8840 - val_acc: 0.7490\n",
      "Epoch 99/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8599 - acc: 0.7694 - val_loss: 0.8867 - val_acc: 0.7470\n",
      "Epoch 100/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8590 - acc: 0.7686 - val_loss: 0.8861 - val_acc: 0.7500\n",
      "Epoch 101/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8579 - acc: 0.7695 - val_loss: 0.8795 - val_acc: 0.7550\n",
      "Epoch 102/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8571 - acc: 0.7702 - val_loss: 0.8816 - val_acc: 0.7490\n",
      "Epoch 103/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8556 - acc: 0.7703 - val_loss: 0.8803 - val_acc: 0.7510\n",
      "Epoch 104/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8543 - acc: 0.7700 - val_loss: 0.8834 - val_acc: 0.7490\n",
      "Epoch 105/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8541 - acc: 0.7694 - val_loss: 0.8805 - val_acc: 0.7580\n",
      "Epoch 106/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8532 - acc: 0.7713 - val_loss: 0.8837 - val_acc: 0.7450\n",
      "Epoch 107/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8524 - acc: 0.7707 - val_loss: 0.8811 - val_acc: 0.7520\n",
      "Epoch 108/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8519 - acc: 0.7714 - val_loss: 0.8764 - val_acc: 0.7540\n",
      "Epoch 109/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8509 - acc: 0.7711 - val_loss: 0.8904 - val_acc: 0.7470\n",
      "Epoch 110/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8502 - acc: 0.7712 - val_loss: 0.8723 - val_acc: 0.7560\n",
      "Epoch 111/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8489 - acc: 0.7718 - val_loss: 0.8726 - val_acc: 0.7560\n",
      "Epoch 112/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8482 - acc: 0.7721 - val_loss: 0.8708 - val_acc: 0.7630\n",
      "Epoch 113/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8477 - acc: 0.7730 - val_loss: 0.8739 - val_acc: 0.7630\n",
      "Epoch 114/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8461 - acc: 0.7730 - val_loss: 0.8696 - val_acc: 0.7550\n",
      "Epoch 115/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.8459 - acc: 0.7729 - val_loss: 0.8734 - val_acc: 0.7590\n",
      "Epoch 116/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.8457 - acc: 0.7735 - val_loss: 0.8684 - val_acc: 0.7640\n",
      "Epoch 117/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8447 - acc: 0.7732 - val_loss: 0.8725 - val_acc: 0.7530\n",
      "Epoch 118/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8434 - acc: 0.7730 - val_loss: 0.8761 - val_acc: 0.7570\n",
      "Epoch 119/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8432 - acc: 0.7746 - val_loss: 0.8766 - val_acc: 0.7580\n",
      "Epoch 120/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8426 - acc: 0.7733 - val_loss: 0.8675 - val_acc: 0.7590\n",
      "Epoch 121/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.8410 - acc: 0.7746 - val_loss: 0.8750 - val_acc: 0.7510\n",
      "Epoch 122/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8403 - acc: 0.7749 - val_loss: 0.8609 - val_acc: 0.7580\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8404 - acc: 0.7747 - val_loss: 0.8598 - val_acc: 0.7530\n",
      "Epoch 124/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8391 - acc: 0.7750 - val_loss: 0.8846 - val_acc: 0.7600\n",
      "Epoch 125/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8386 - acc: 0.7753 - val_loss: 0.8641 - val_acc: 0.7600\n",
      "Epoch 126/150\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.8385 - acc: 0.7746 - val_loss: 0.8573 - val_acc: 0.7640\n",
      "Epoch 127/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.8374 - acc: 0.7774 - val_loss: 0.8677 - val_acc: 0.7580\n",
      "Epoch 128/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.8381 - acc: 0.7747 - val_loss: 0.8620 - val_acc: 0.7550\n",
      "Epoch 129/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8366 - acc: 0.7758 - val_loss: 0.8541 - val_acc: 0.7630\n",
      "Epoch 130/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8364 - acc: 0.7751 - val_loss: 0.8583 - val_acc: 0.7550\n",
      "Epoch 131/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8355 - acc: 0.7756 - val_loss: 0.8557 - val_acc: 0.7600\n",
      "Epoch 132/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8359 - acc: 0.7761 - val_loss: 0.8705 - val_acc: 0.7560\n",
      "Epoch 133/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8338 - acc: 0.7764 - val_loss: 0.8568 - val_acc: 0.7690\n",
      "Epoch 134/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8333 - acc: 0.7773 - val_loss: 0.8554 - val_acc: 0.7650\n",
      "Epoch 135/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8332 - acc: 0.7766 - val_loss: 0.8524 - val_acc: 0.7660\n",
      "Epoch 136/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8322 - acc: 0.7776 - val_loss: 0.8526 - val_acc: 0.7610\n",
      "Epoch 137/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8326 - acc: 0.7765 - val_loss: 0.8650 - val_acc: 0.7620\n",
      "Epoch 138/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8317 - acc: 0.7777 - val_loss: 0.8586 - val_acc: 0.7560\n",
      "Epoch 139/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8307 - acc: 0.7780 - val_loss: 0.8562 - val_acc: 0.7710\n",
      "Epoch 140/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8297 - acc: 0.7784 - val_loss: 0.8839 - val_acc: 0.7550\n",
      "Epoch 141/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8283 - acc: 0.7778 - val_loss: 0.8535 - val_acc: 0.7700\n",
      "Epoch 142/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8295 - acc: 0.7774 - val_loss: 0.8463 - val_acc: 0.7720\n",
      "Epoch 143/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8284 - acc: 0.7782 - val_loss: 0.8489 - val_acc: 0.7780\n",
      "Epoch 144/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8295 - acc: 0.7787 - val_loss: 0.8575 - val_acc: 0.7590\n",
      "Epoch 145/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8273 - acc: 0.7787 - val_loss: 0.8563 - val_acc: 0.7610\n",
      "Epoch 146/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8278 - acc: 0.7785 - val_loss: 0.8542 - val_acc: 0.7660\n",
      "Epoch 147/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8271 - acc: 0.7790 - val_loss: 0.8429 - val_acc: 0.7740\n",
      "Epoch 148/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8255 - acc: 0.7797 - val_loss: 0.8560 - val_acc: 0.7680\n",
      "Epoch 149/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8256 - acc: 0.7795 - val_loss: 0.8522 - val_acc: 0.7630\n",
      "Epoch 150/150\n",
      "225/225 [==============================] - 1s 5ms/step - loss: 0.8246 - acc: 0.7793 - val_loss: 0.8507 - val_acc: 0.7610\n"
     ]
    }
   ],
   "source": [
    "random.seed(123)\n",
    "L1_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L1_model.add(layers.Dense(50, activation='relu',\n",
    "                          input_shape=(2000,),\n",
    "                          kernel_regularizer=regularizers.L1(lambda_coeff)))\n",
    "\n",
    "# Add a hidden layer\n",
    "L1_model.add(layers.Dense(25, activation='relu',\n",
    "                          kernel_regularizer=regularizers.L1(lambda_coeff)))\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='SGD', \n",
    "                 loss='categorical_crossentropy', \n",
    "                 metrics=['acc'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train_tokens, \n",
    "                            y_train_lb, \n",
    "                            epochs=150, \n",
    "                            batch_size=256, \n",
    "                            validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training as well as the validation accuracy for the L1 model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the training and validation accuracy don't diverge as much as before. Unfortunately, the validation accuracy isn't still that good. Next, experiment with dropout regularization to see if it offers any advantages. \n",
    "\n",
    "\n",
    "## Dropout Regularization \n",
    "\n",
    "It's time to try another technique: applying dropout to layers. As discussed in the earlier lesson, this involves setting a certain proportion of units in each layer to zero. In the following cell: \n",
    "\n",
    "- Apply a dropout rate of 30% to the input layer \n",
    "- Add a first hidden layer with 50 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the first hidden layer \n",
    "- Add a second hidden layer with 25 units and `'relu'` activation \n",
    "- Apply a dropout rate of 30% to the second hidden layer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.9185 - acc: 0.1987 - val_loss: 1.8648 - val_acc: 0.2610\n",
      "Epoch 2/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.8376 - acc: 0.2507 - val_loss: 1.7310 - val_acc: 0.3830\n",
      "Epoch 3/150\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.7266 - acc: 0.3100 - val_loss: 1.5698 - val_acc: 0.4980\n",
      "Epoch 4/150\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 1.6112 - acc: 0.3706 - val_loss: 1.4097 - val_acc: 0.5930\n",
      "Epoch 5/150\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 1.4944 - acc: 0.4287 - val_loss: 1.2573 - val_acc: 0.6510\n",
      "Epoch 6/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.4000 - acc: 0.4724 - val_loss: 1.1333 - val_acc: 0.6760\n",
      "Epoch 7/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.3169 - acc: 0.5079 - val_loss: 1.0346 - val_acc: 0.7020\n",
      "Epoch 8/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.2470 - acc: 0.5342 - val_loss: 0.9543 - val_acc: 0.7180\n",
      "Epoch 9/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.1863 - acc: 0.5593 - val_loss: 0.8851 - val_acc: 0.7280\n",
      "Epoch 10/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.1352 - acc: 0.5791 - val_loss: 0.8319 - val_acc: 0.7370\n",
      "Epoch 11/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.0962 - acc: 0.5942 - val_loss: 0.7951 - val_acc: 0.7350\n",
      "Epoch 12/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.0596 - acc: 0.6099 - val_loss: 0.7628 - val_acc: 0.7430\n",
      "Epoch 13/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.0321 - acc: 0.6204 - val_loss: 0.7393 - val_acc: 0.7450\n",
      "Epoch 14/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 1.0085 - acc: 0.6285 - val_loss: 0.7148 - val_acc: 0.7460\n",
      "Epoch 15/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.9851 - acc: 0.6377 - val_loss: 0.7008 - val_acc: 0.7480\n",
      "Epoch 16/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.9689 - acc: 0.6430 - val_loss: 0.6854 - val_acc: 0.7520\n",
      "Epoch 17/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.9462 - acc: 0.6515 - val_loss: 0.6725 - val_acc: 0.7550\n",
      "Epoch 18/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.9291 - acc: 0.6594 - val_loss: 0.6583 - val_acc: 0.7510\n",
      "Epoch 19/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.9150 - acc: 0.6629 - val_loss: 0.6496 - val_acc: 0.7560\n",
      "Epoch 20/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.9050 - acc: 0.6666 - val_loss: 0.6435 - val_acc: 0.7570\n",
      "Epoch 21/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8936 - acc: 0.6685 - val_loss: 0.6353 - val_acc: 0.7560\n",
      "Epoch 22/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8832 - acc: 0.6753 - val_loss: 0.6294 - val_acc: 0.7570\n",
      "Epoch 23/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8718 - acc: 0.6781 - val_loss: 0.6215 - val_acc: 0.7570\n",
      "Epoch 24/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8642 - acc: 0.6823 - val_loss: 0.6169 - val_acc: 0.7590\n",
      "Epoch 25/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8561 - acc: 0.6839 - val_loss: 0.6112 - val_acc: 0.7600\n",
      "Epoch 26/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8497 - acc: 0.6875 - val_loss: 0.6109 - val_acc: 0.7600\n",
      "Epoch 27/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8454 - acc: 0.6895 - val_loss: 0.6042 - val_acc: 0.7610\n",
      "Epoch 28/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8319 - acc: 0.6926 - val_loss: 0.5998 - val_acc: 0.7550\n",
      "Epoch 29/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8256 - acc: 0.6957 - val_loss: 0.5990 - val_acc: 0.7620\n",
      "Epoch 30/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.8244 - acc: 0.6959 - val_loss: 0.5960 - val_acc: 0.7610\n",
      "Epoch 31/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8161 - acc: 0.6987 - val_loss: 0.5911 - val_acc: 0.7620\n",
      "Epoch 32/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.8113 - acc: 0.7018 - val_loss: 0.5876 - val_acc: 0.7640\n",
      "Epoch 33/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.8105 - acc: 0.7022 - val_loss: 0.5893 - val_acc: 0.7610\n",
      "Epoch 34/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.8044 - acc: 0.7043 - val_loss: 0.5821 - val_acc: 0.7650\n",
      "Epoch 35/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7938 - acc: 0.7085 - val_loss: 0.5822 - val_acc: 0.7620\n",
      "Epoch 36/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7943 - acc: 0.7062 - val_loss: 0.5805 - val_acc: 0.7640\n",
      "Epoch 37/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7880 - acc: 0.7097 - val_loss: 0.5805 - val_acc: 0.7600\n",
      "Epoch 38/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7803 - acc: 0.7127 - val_loss: 0.5772 - val_acc: 0.7610\n",
      "Epoch 39/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7736 - acc: 0.7157 - val_loss: 0.5754 - val_acc: 0.7640\n",
      "Epoch 40/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7790 - acc: 0.7134 - val_loss: 0.5767 - val_acc: 0.7650\n",
      "Epoch 41/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7744 - acc: 0.7126 - val_loss: 0.5751 - val_acc: 0.7660\n",
      "Epoch 42/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7672 - acc: 0.7167 - val_loss: 0.5723 - val_acc: 0.7670\n",
      "Epoch 43/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7680 - acc: 0.7169 - val_loss: 0.5704 - val_acc: 0.7650\n",
      "Epoch 44/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7580 - acc: 0.7194 - val_loss: 0.5717 - val_acc: 0.7600\n",
      "Epoch 45/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7611 - acc: 0.7182 - val_loss: 0.5709 - val_acc: 0.7600\n",
      "Epoch 46/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7571 - acc: 0.7215 - val_loss: 0.5716 - val_acc: 0.7650\n",
      "Epoch 47/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7547 - acc: 0.7234 - val_loss: 0.5690 - val_acc: 0.7620\n",
      "Epoch 48/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7482 - acc: 0.7221 - val_loss: 0.5669 - val_acc: 0.7630\n",
      "Epoch 49/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7485 - acc: 0.7216 - val_loss: 0.5629 - val_acc: 0.7710\n",
      "Epoch 50/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7416 - acc: 0.7254 - val_loss: 0.5660 - val_acc: 0.7680\n",
      "Epoch 51/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7441 - acc: 0.7223 - val_loss: 0.5611 - val_acc: 0.7710\n",
      "Epoch 52/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7380 - acc: 0.7281 - val_loss: 0.5634 - val_acc: 0.7670\n",
      "Epoch 53/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7332 - acc: 0.7276 - val_loss: 0.5617 - val_acc: 0.7690\n",
      "Epoch 54/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7344 - acc: 0.7274 - val_loss: 0.5605 - val_acc: 0.7750\n",
      "Epoch 55/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7308 - acc: 0.7290 - val_loss: 0.5589 - val_acc: 0.7740\n",
      "Epoch 56/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7301 - acc: 0.7311 - val_loss: 0.5599 - val_acc: 0.7690\n",
      "Epoch 57/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7303 - acc: 0.7297 - val_loss: 0.5576 - val_acc: 0.7690\n",
      "Epoch 58/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7279 - acc: 0.7308 - val_loss: 0.5581 - val_acc: 0.7740\n",
      "Epoch 59/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7241 - acc: 0.7335 - val_loss: 0.5578 - val_acc: 0.7630\n",
      "Epoch 60/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7166 - acc: 0.7362 - val_loss: 0.5548 - val_acc: 0.7690\n",
      "Epoch 61/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7169 - acc: 0.7350 - val_loss: 0.5545 - val_acc: 0.7720\n",
      "Epoch 62/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 2s 8ms/step - loss: 0.7123 - acc: 0.7341 - val_loss: 0.5571 - val_acc: 0.7720\n",
      "Epoch 63/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7137 - acc: 0.7363 - val_loss: 0.5541 - val_acc: 0.7750\n",
      "Epoch 64/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7132 - acc: 0.7354 - val_loss: 0.5526 - val_acc: 0.7780\n",
      "Epoch 65/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7121 - acc: 0.7369 - val_loss: 0.5546 - val_acc: 0.7810\n",
      "Epoch 66/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7145 - acc: 0.7348 - val_loss: 0.5534 - val_acc: 0.7790\n",
      "Epoch 67/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7123 - acc: 0.7366 - val_loss: 0.5558 - val_acc: 0.7730\n",
      "Epoch 68/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7054 - acc: 0.7370 - val_loss: 0.5553 - val_acc: 0.7700\n",
      "Epoch 69/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7103 - acc: 0.7386 - val_loss: 0.5551 - val_acc: 0.7690\n",
      "Epoch 70/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7021 - acc: 0.7387 - val_loss: 0.5516 - val_acc: 0.7800\n",
      "Epoch 71/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7042 - acc: 0.7379 - val_loss: 0.5522 - val_acc: 0.7870\n",
      "Epoch 72/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6927 - acc: 0.7421 - val_loss: 0.5488 - val_acc: 0.7740\n",
      "Epoch 73/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.7015 - acc: 0.7393 - val_loss: 0.5506 - val_acc: 0.7770\n",
      "Epoch 74/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6933 - acc: 0.7443 - val_loss: 0.5477 - val_acc: 0.7760\n",
      "Epoch 75/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6933 - acc: 0.7426 - val_loss: 0.5465 - val_acc: 0.7800\n",
      "Epoch 76/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6956 - acc: 0.7430 - val_loss: 0.5463 - val_acc: 0.7960\n",
      "Epoch 77/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6972 - acc: 0.7415 - val_loss: 0.5468 - val_acc: 0.7830\n",
      "Epoch 78/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6963 - acc: 0.7408 - val_loss: 0.5472 - val_acc: 0.7770\n",
      "Epoch 79/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6916 - acc: 0.7431 - val_loss: 0.5479 - val_acc: 0.7830\n",
      "Epoch 80/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6871 - acc: 0.7441 - val_loss: 0.5494 - val_acc: 0.7870\n",
      "Epoch 81/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6866 - acc: 0.7447 - val_loss: 0.5469 - val_acc: 0.7870\n",
      "Epoch 82/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6882 - acc: 0.7431 - val_loss: 0.5509 - val_acc: 0.7790\n",
      "Epoch 83/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6924 - acc: 0.7426 - val_loss: 0.5483 - val_acc: 0.7810\n",
      "Epoch 84/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6877 - acc: 0.7459 - val_loss: 0.5462 - val_acc: 0.7780\n",
      "Epoch 85/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6833 - acc: 0.7465 - val_loss: 0.5465 - val_acc: 0.7780\n",
      "Epoch 86/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6823 - acc: 0.7458 - val_loss: 0.5458 - val_acc: 0.7790\n",
      "Epoch 87/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6818 - acc: 0.7468 - val_loss: 0.5453 - val_acc: 0.7940\n",
      "Epoch 88/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6820 - acc: 0.7479 - val_loss: 0.5456 - val_acc: 0.7920\n",
      "Epoch 89/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6771 - acc: 0.7486 - val_loss: 0.5435 - val_acc: 0.7780\n",
      "Epoch 90/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6734 - acc: 0.7492 - val_loss: 0.5459 - val_acc: 0.7870\n",
      "Epoch 91/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6758 - acc: 0.7494 - val_loss: 0.5465 - val_acc: 0.7830\n",
      "Epoch 92/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6722 - acc: 0.7520 - val_loss: 0.5444 - val_acc: 0.7940\n",
      "Epoch 93/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6723 - acc: 0.7487 - val_loss: 0.5455 - val_acc: 0.7890\n",
      "Epoch 94/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6683 - acc: 0.7514 - val_loss: 0.5428 - val_acc: 0.7870\n",
      "Epoch 95/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6667 - acc: 0.7522 - val_loss: 0.5426 - val_acc: 0.7850\n",
      "Epoch 96/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6732 - acc: 0.7521 - val_loss: 0.5429 - val_acc: 0.7920\n",
      "Epoch 97/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6649 - acc: 0.7534 - val_loss: 0.5434 - val_acc: 0.7880\n",
      "Epoch 98/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6643 - acc: 0.7531 - val_loss: 0.5448 - val_acc: 0.7980\n",
      "Epoch 99/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6643 - acc: 0.7545 - val_loss: 0.5441 - val_acc: 0.7870\n",
      "Epoch 100/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6652 - acc: 0.7543 - val_loss: 0.5414 - val_acc: 0.7920\n",
      "Epoch 101/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6635 - acc: 0.7559 - val_loss: 0.5415 - val_acc: 0.7930\n",
      "Epoch 102/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6634 - acc: 0.7536 - val_loss: 0.5424 - val_acc: 0.7910\n",
      "Epoch 103/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6615 - acc: 0.7542 - val_loss: 0.5414 - val_acc: 0.7940\n",
      "Epoch 104/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6667 - acc: 0.7551 - val_loss: 0.5404 - val_acc: 0.7910\n",
      "Epoch 105/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6626 - acc: 0.7568 - val_loss: 0.5438 - val_acc: 0.7900\n",
      "Epoch 106/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6576 - acc: 0.7584 - val_loss: 0.5408 - val_acc: 0.7930\n",
      "Epoch 107/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6588 - acc: 0.7561 - val_loss: 0.5360 - val_acc: 0.7870\n",
      "Epoch 108/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6605 - acc: 0.7568 - val_loss: 0.5389 - val_acc: 0.7870\n",
      "Epoch 109/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6541 - acc: 0.7573 - val_loss: 0.5378 - val_acc: 0.7890\n",
      "Epoch 110/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6582 - acc: 0.7582 - val_loss: 0.5375 - val_acc: 0.7880\n",
      "Epoch 111/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6554 - acc: 0.7569 - val_loss: 0.5377 - val_acc: 0.7910\n",
      "Epoch 112/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6606 - acc: 0.7565 - val_loss: 0.5371 - val_acc: 0.7890\n",
      "Epoch 113/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6547 - acc: 0.7591 - val_loss: 0.5386 - val_acc: 0.7880\n",
      "Epoch 114/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6522 - acc: 0.7600 - val_loss: 0.5354 - val_acc: 0.7940\n",
      "Epoch 115/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6513 - acc: 0.7609 - val_loss: 0.5368 - val_acc: 0.7910\n",
      "Epoch 116/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6544 - acc: 0.7613 - val_loss: 0.5376 - val_acc: 0.7960\n",
      "Epoch 117/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6545 - acc: 0.7609 - val_loss: 0.5384 - val_acc: 0.7890\n",
      "Epoch 118/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6552 - acc: 0.7564 - val_loss: 0.5384 - val_acc: 0.7990\n",
      "Epoch 119/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6515 - acc: 0.7594 - val_loss: 0.5357 - val_acc: 0.7960\n",
      "Epoch 120/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6496 - acc: 0.7622 - val_loss: 0.5364 - val_acc: 0.7950\n",
      "Epoch 121/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6476 - acc: 0.7619 - val_loss: 0.5339 - val_acc: 0.7970\n",
      "Epoch 122/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6450 - acc: 0.7648 - val_loss: 0.5322 - val_acc: 0.7990\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6490 - acc: 0.7632 - val_loss: 0.5339 - val_acc: 0.8030\n",
      "Epoch 124/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6449 - acc: 0.7619 - val_loss: 0.5324 - val_acc: 0.7970\n",
      "Epoch 125/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6429 - acc: 0.7644 - val_loss: 0.5313 - val_acc: 0.7950\n",
      "Epoch 126/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6415 - acc: 0.7653 - val_loss: 0.5315 - val_acc: 0.7970\n",
      "Epoch 127/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6435 - acc: 0.7636 - val_loss: 0.5313 - val_acc: 0.7980\n",
      "Epoch 128/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6422 - acc: 0.7634 - val_loss: 0.5319 - val_acc: 0.7970\n",
      "Epoch 129/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6411 - acc: 0.7654 - val_loss: 0.5318 - val_acc: 0.7980\n",
      "Epoch 130/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6451 - acc: 0.7649 - val_loss: 0.5316 - val_acc: 0.7960\n",
      "Epoch 131/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6365 - acc: 0.7666 - val_loss: 0.5307 - val_acc: 0.8000\n",
      "Epoch 132/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6369 - acc: 0.7677 - val_loss: 0.5297 - val_acc: 0.7980\n",
      "Epoch 133/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6414 - acc: 0.7654 - val_loss: 0.5316 - val_acc: 0.8000\n",
      "Epoch 134/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6361 - acc: 0.7671 - val_loss: 0.5304 - val_acc: 0.7990\n",
      "Epoch 135/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6401 - acc: 0.7649 - val_loss: 0.5279 - val_acc: 0.8080\n",
      "Epoch 136/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6397 - acc: 0.7675 - val_loss: 0.5276 - val_acc: 0.8060\n",
      "Epoch 137/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6366 - acc: 0.7669 - val_loss: 0.5291 - val_acc: 0.8030\n",
      "Epoch 138/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6305 - acc: 0.7690 - val_loss: 0.5278 - val_acc: 0.8030\n",
      "Epoch 139/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6288 - acc: 0.7692 - val_loss: 0.5288 - val_acc: 0.8070\n",
      "Epoch 140/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6343 - acc: 0.7670 - val_loss: 0.5290 - val_acc: 0.8050\n",
      "Epoch 141/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6268 - acc: 0.7708 - val_loss: 0.5301 - val_acc: 0.8030\n",
      "Epoch 142/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6307 - acc: 0.7678 - val_loss: 0.5289 - val_acc: 0.8080\n",
      "Epoch 143/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6298 - acc: 0.7708 - val_loss: 0.5282 - val_acc: 0.8030\n",
      "Epoch 144/150\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 0.6297 - acc: 0.7706 - val_loss: 0.5281 - val_acc: 0.8100\n",
      "Epoch 145/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6277 - acc: 0.7719 - val_loss: 0.5281 - val_acc: 0.8100\n",
      "Epoch 146/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6296 - acc: 0.7708 - val_loss: 0.5292 - val_acc: 0.8070\n",
      "Epoch 147/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6278 - acc: 0.7715 - val_loss: 0.5264 - val_acc: 0.8050\n",
      "Epoch 148/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6269 - acc: 0.7704 - val_loss: 0.5275 - val_acc: 0.8080\n",
      "Epoch 149/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6304 - acc: 0.7679 - val_loss: 0.5285 - val_acc: 0.7990\n",
      "Epoch 150/150\n",
      "225/225 [==============================] - 2s 7ms/step - loss: 0.6249 - acc: 0.7727 - val_loss: 0.5266 - val_acc: 0.8130\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take about a minute to run\n",
    "random.seed(123)\n",
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "dropout_model.add(layers.Dropout(0.3, input_shape=(2000,)))\n",
    "\n",
    "# Add the first hidden layer\n",
    "dropout_model.add(layers.Dense(50, activation='relu'))\n",
    "\n",
    "# Implement dropout to the first hidden layer \n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add the second hidden layer\n",
    "dropout_model.add(layers.Dense(25, activation='relu'))\n",
    "\n",
    "# Implement dropout to the second hidden layer \n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='SGD', \n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['acc'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train_tokens, \n",
    "                                      y_train_lb, \n",
    "                                      epochs=150, \n",
    "                                      batch_size=256, \n",
    "                                      validation_data=(X_val_tokens, y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797/1797 [==============================] - 2s 1ms/step - loss: 0.4033 - acc: 0.8607\n",
      "Training Loss: 0.403 \n",
      "Training Accuracy: 0.861\n",
      "----------\n",
      "47/47 [==============================] - 0s 2ms/step - loss: 0.5041 - acc: 0.7940\n",
      "Test Loss: 0.504 \n",
      "Test Accuracy: 0.794\n"
     ]
    }
   ],
   "source": [
    "results_train = dropout_model.evaluate(X_train_tokens, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = dropout_model.evaluate(X_test_tokens, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here that the validation performance has improved again, and the training and test accuracy are very close!  \n",
    "\n",
    "## Bigger Data? \n",
    "\n",
    "Finally, let's examine if we can improve the model's performance just by adding more data. We've quadrapled the sample dataset from 10,000 to 40,000 observations, and all you need to do is run the code! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bigger_sample = df.sample(40000, random_state=123)\n",
    "\n",
    "X = df['Consumer complaint narrative']\n",
    "y = df['Product']\n",
    "\n",
    "# Train-test split\n",
    "X_train_bigger, X_test_bigger, y_train_bigger, y_test_bigger = train_test_split(X, \n",
    "                                                                                y, \n",
    "                                                                                test_size=6000, \n",
    "                                                                                random_state=42)\n",
    "\n",
    "# Validation set\n",
    "X_train_final_bigger, X_val_bigger, y_train_final_bigger, y_val_bigger = train_test_split(X_train_bigger, \n",
    "                                                                                          y_train_bigger, \n",
    "                                                                                          test_size=4000, \n",
    "                                                                                          random_state=42)\n",
    "\n",
    "\n",
    "# One-hot encoding of the complaints\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(X_train_final_bigger)\n",
    "\n",
    "X_train_tokens_bigger = tokenizer.texts_to_matrix(X_train_final_bigger, mode='binary')\n",
    "X_val_tokens_bigger = tokenizer.texts_to_matrix(X_val_bigger, mode='binary')\n",
    "X_test_tokens_bigger = tokenizer.texts_to_matrix(X_test_bigger, mode='binary')\n",
    "\n",
    "# One-hot encoding of products\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train_final_bigger)\n",
    "\n",
    "y_train_lb_bigger = to_categorical(lb.transform(y_train_final_bigger))[:, :, 1]\n",
    "y_val_lb_bigger = to_categorical(lb.transform(y_val_bigger))[:, :, 1]\n",
    "y_test_lb_bigger = to_categorical(lb.transform(y_test_bigger))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 1.9011 - acc: 0.2111 - val_loss: 1.8480 - val_acc: 0.2715\n",
      "Epoch 2/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 1.7539 - acc: 0.3620 - val_loss: 1.6523 - val_acc: 0.4372\n",
      "Epoch 3/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 1.4911 - acc: 0.5249 - val_loss: 1.3459 - val_acc: 0.5913\n",
      "Epoch 4/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 1.1853 - acc: 0.6388 - val_loss: 1.0732 - val_acc: 0.6712\n",
      "Epoch 5/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.9651 - acc: 0.6924 - val_loss: 0.9106 - val_acc: 0.7023\n",
      "Epoch 6/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.8340 - acc: 0.7219 - val_loss: 0.8117 - val_acc: 0.7230\n",
      "Epoch 7/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.7550 - acc: 0.7383 - val_loss: 0.7502 - val_acc: 0.7355\n",
      "Epoch 8/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.7046 - acc: 0.7502 - val_loss: 0.7115 - val_acc: 0.7477\n",
      "Epoch 9/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.6690 - acc: 0.7607 - val_loss: 0.6881 - val_acc: 0.7563\n",
      "Epoch 10/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.6424 - acc: 0.7670 - val_loss: 0.6638 - val_acc: 0.7620\n",
      "Epoch 11/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.6212 - acc: 0.7754 - val_loss: 0.6477 - val_acc: 0.7660\n",
      "Epoch 12/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.6037 - acc: 0.7813 - val_loss: 0.6363 - val_acc: 0.7680\n",
      "Epoch 13/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5889 - acc: 0.7864 - val_loss: 0.6225 - val_acc: 0.7750\n",
      "Epoch 14/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.5757 - acc: 0.7924 - val_loss: 0.6130 - val_acc: 0.7775\n",
      "Epoch 15/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5640 - acc: 0.7958 - val_loss: 0.6052 - val_acc: 0.7805\n",
      "Epoch 16/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5537 - acc: 0.8002 - val_loss: 0.6000 - val_acc: 0.7840\n",
      "Epoch 17/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5445 - acc: 0.8043 - val_loss: 0.5929 - val_acc: 0.7868\n",
      "Epoch 18/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5360 - acc: 0.8072 - val_loss: 0.5857 - val_acc: 0.7885\n",
      "Epoch 19/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5278 - acc: 0.8113 - val_loss: 0.5794 - val_acc: 0.7897\n",
      "Epoch 20/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5204 - acc: 0.8134 - val_loss: 0.5769 - val_acc: 0.7918\n",
      "Epoch 21/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5135 - acc: 0.8152 - val_loss: 0.5730 - val_acc: 0.7952\n",
      "Epoch 22/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5071 - acc: 0.8180 - val_loss: 0.5686 - val_acc: 0.7955\n",
      "Epoch 23/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.5008 - acc: 0.8210 - val_loss: 0.5628 - val_acc: 0.7952\n",
      "Epoch 24/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4953 - acc: 0.8237 - val_loss: 0.5638 - val_acc: 0.8002\n",
      "Epoch 25/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4901 - acc: 0.8250 - val_loss: 0.5605 - val_acc: 0.8008\n",
      "Epoch 26/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4850 - acc: 0.8279 - val_loss: 0.5557 - val_acc: 0.8023\n",
      "Epoch 27/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4799 - acc: 0.8290 - val_loss: 0.5541 - val_acc: 0.8027\n",
      "Epoch 28/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4753 - acc: 0.8314 - val_loss: 0.5569 - val_acc: 0.8027\n",
      "Epoch 29/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4711 - acc: 0.8331 - val_loss: 0.5531 - val_acc: 0.8027\n",
      "Epoch 30/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4668 - acc: 0.8339 - val_loss: 0.5515 - val_acc: 0.7995\n",
      "Epoch 31/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4630 - acc: 0.8366 - val_loss: 0.5455 - val_acc: 0.8065\n",
      "Epoch 32/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4591 - acc: 0.8380 - val_loss: 0.5464 - val_acc: 0.8083\n",
      "Epoch 33/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4553 - acc: 0.8395 - val_loss: 0.5429 - val_acc: 0.8073\n",
      "Epoch 34/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4517 - acc: 0.8409 - val_loss: 0.5448 - val_acc: 0.8087\n",
      "Epoch 35/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4486 - acc: 0.8419 - val_loss: 0.5437 - val_acc: 0.8062\n",
      "Epoch 36/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4453 - acc: 0.8432 - val_loss: 0.5427 - val_acc: 0.8130\n",
      "Epoch 37/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4422 - acc: 0.8445 - val_loss: 0.5385 - val_acc: 0.8105\n",
      "Epoch 38/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4389 - acc: 0.8463 - val_loss: 0.5388 - val_acc: 0.8102\n",
      "Epoch 39/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4362 - acc: 0.8469 - val_loss: 0.5378 - val_acc: 0.8138\n",
      "Epoch 40/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4334 - acc: 0.8470 - val_loss: 0.5388 - val_acc: 0.8145\n",
      "Epoch 41/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4306 - acc: 0.8485 - val_loss: 0.5449 - val_acc: 0.8100\n",
      "Epoch 42/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4282 - acc: 0.8507 - val_loss: 0.5379 - val_acc: 0.8150\n",
      "Epoch 43/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4257 - acc: 0.8510 - val_loss: 0.5370 - val_acc: 0.8127\n",
      "Epoch 44/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4232 - acc: 0.8525 - val_loss: 0.5349 - val_acc: 0.8152\n",
      "Epoch 45/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4206 - acc: 0.8532 - val_loss: 0.5402 - val_acc: 0.8135\n",
      "Epoch 46/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4182 - acc: 0.8534 - val_loss: 0.5367 - val_acc: 0.8112\n",
      "Epoch 47/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4159 - acc: 0.8541 - val_loss: 0.5334 - val_acc: 0.8125\n",
      "Epoch 48/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4140 - acc: 0.8552 - val_loss: 0.5380 - val_acc: 0.8127\n",
      "Epoch 49/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4118 - acc: 0.8560 - val_loss: 0.5387 - val_acc: 0.8133\n",
      "Epoch 50/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4098 - acc: 0.8567 - val_loss: 0.5397 - val_acc: 0.8125\n",
      "Epoch 51/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4074 - acc: 0.8580 - val_loss: 0.5380 - val_acc: 0.8083\n",
      "Epoch 52/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4056 - acc: 0.8573 - val_loss: 0.5362 - val_acc: 0.8152\n",
      "Epoch 53/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4036 - acc: 0.8593 - val_loss: 0.5348 - val_acc: 0.8115\n",
      "Epoch 54/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.4019 - acc: 0.8595 - val_loss: 0.5357 - val_acc: 0.8120\n",
      "Epoch 55/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.4001 - acc: 0.8603 - val_loss: 0.5339 - val_acc: 0.8138\n",
      "Epoch 56/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3981 - acc: 0.8611 - val_loss: 0.5348 - val_acc: 0.8110\n",
      "Epoch 57/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3962 - acc: 0.8620 - val_loss: 0.5377 - val_acc: 0.8077\n",
      "Epoch 58/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3947 - acc: 0.8623 - val_loss: 0.5357 - val_acc: 0.8142\n",
      "Epoch 59/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3931 - acc: 0.8626 - val_loss: 0.5351 - val_acc: 0.8160\n",
      "Epoch 60/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3915 - acc: 0.8642 - val_loss: 0.5369 - val_acc: 0.8120\n",
      "Epoch 61/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3898 - acc: 0.8640 - val_loss: 0.5371 - val_acc: 0.8138\n",
      "Epoch 62/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3882 - acc: 0.8654 - val_loss: 0.5388 - val_acc: 0.8138\n",
      "Epoch 63/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3866 - acc: 0.8647 - val_loss: 0.5345 - val_acc: 0.8120\n",
      "Epoch 64/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3852 - acc: 0.8657 - val_loss: 0.5346 - val_acc: 0.8140\n",
      "Epoch 65/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3837 - acc: 0.8659 - val_loss: 0.5353 - val_acc: 0.8133\n",
      "Epoch 66/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3818 - acc: 0.8668 - val_loss: 0.5420 - val_acc: 0.8158\n",
      "Epoch 67/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3808 - acc: 0.8670 - val_loss: 0.5395 - val_acc: 0.8135\n",
      "Epoch 68/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3790 - acc: 0.8683 - val_loss: 0.5364 - val_acc: 0.8125\n",
      "Epoch 69/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3777 - acc: 0.8673 - val_loss: 0.5423 - val_acc: 0.8125\n",
      "Epoch 70/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3767 - acc: 0.8689 - val_loss: 0.5421 - val_acc: 0.8127\n",
      "Epoch 71/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3751 - acc: 0.8686 - val_loss: 0.5387 - val_acc: 0.8115\n",
      "Epoch 72/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3738 - acc: 0.8687 - val_loss: 0.5471 - val_acc: 0.8115\n",
      "Epoch 73/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3722 - acc: 0.8699 - val_loss: 0.5454 - val_acc: 0.8098\n",
      "Epoch 74/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3711 - acc: 0.8693 - val_loss: 0.5407 - val_acc: 0.8138\n",
      "Epoch 75/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3696 - acc: 0.8707 - val_loss: 0.5400 - val_acc: 0.8150\n",
      "Epoch 76/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3687 - acc: 0.8700 - val_loss: 0.5409 - val_acc: 0.8133\n",
      "Epoch 77/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3675 - acc: 0.8715 - val_loss: 0.5417 - val_acc: 0.8135\n",
      "Epoch 78/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3662 - acc: 0.8717 - val_loss: 0.5459 - val_acc: 0.8100\n",
      "Epoch 79/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3650 - acc: 0.8718 - val_loss: 0.5482 - val_acc: 0.8110\n",
      "Epoch 80/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3636 - acc: 0.8724 - val_loss: 0.5450 - val_acc: 0.8092\n",
      "Epoch 81/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3629 - acc: 0.8725 - val_loss: 0.5445 - val_acc: 0.8110\n",
      "Epoch 82/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3612 - acc: 0.8732 - val_loss: 0.5446 - val_acc: 0.8120\n",
      "Epoch 83/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3602 - acc: 0.8733 - val_loss: 0.5504 - val_acc: 0.8108\n",
      "Epoch 84/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3593 - acc: 0.8736 - val_loss: 0.5495 - val_acc: 0.8092\n",
      "Epoch 85/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3581 - acc: 0.8745 - val_loss: 0.5455 - val_acc: 0.8112\n",
      "Epoch 86/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3563 - acc: 0.8754 - val_loss: 0.5459 - val_acc: 0.8127\n",
      "Epoch 87/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3557 - acc: 0.8758 - val_loss: 0.5502 - val_acc: 0.8123\n",
      "Epoch 88/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3545 - acc: 0.8749 - val_loss: 0.5505 - val_acc: 0.8108\n",
      "Epoch 89/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3533 - acc: 0.8758 - val_loss: 0.5498 - val_acc: 0.8140\n",
      "Epoch 90/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3527 - acc: 0.8760 - val_loss: 0.5567 - val_acc: 0.8135\n",
      "Epoch 91/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3517 - acc: 0.8763 - val_loss: 0.5508 - val_acc: 0.8133\n",
      "Epoch 92/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3504 - acc: 0.8770 - val_loss: 0.5544 - val_acc: 0.8138\n",
      "Epoch 93/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3492 - acc: 0.8772 - val_loss: 0.5541 - val_acc: 0.8112\n",
      "Epoch 94/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3484 - acc: 0.8780 - val_loss: 0.5539 - val_acc: 0.8108\n",
      "Epoch 95/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3473 - acc: 0.8780 - val_loss: 0.5535 - val_acc: 0.8127\n",
      "Epoch 96/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3463 - acc: 0.8775 - val_loss: 0.5552 - val_acc: 0.8115\n",
      "Epoch 97/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3453 - acc: 0.8786 - val_loss: 0.5542 - val_acc: 0.8115\n",
      "Epoch 98/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3443 - acc: 0.8800 - val_loss: 0.5611 - val_acc: 0.8112\n",
      "Epoch 99/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3435 - acc: 0.8792 - val_loss: 0.5591 - val_acc: 0.8112\n",
      "Epoch 100/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3428 - acc: 0.8798 - val_loss: 0.5586 - val_acc: 0.8100\n",
      "Epoch 101/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3414 - acc: 0.8807 - val_loss: 0.5565 - val_acc: 0.8098\n",
      "Epoch 102/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3404 - acc: 0.8809 - val_loss: 0.5591 - val_acc: 0.8085\n",
      "Epoch 103/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3395 - acc: 0.8813 - val_loss: 0.5645 - val_acc: 0.8055\n",
      "Epoch 104/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3387 - acc: 0.8810 - val_loss: 0.5668 - val_acc: 0.8043\n",
      "Epoch 105/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3377 - acc: 0.8822 - val_loss: 0.5600 - val_acc: 0.8083\n",
      "Epoch 106/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3368 - acc: 0.8817 - val_loss: 0.5610 - val_acc: 0.8080\n",
      "Epoch 107/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3357 - acc: 0.8827 - val_loss: 0.5664 - val_acc: 0.8138\n",
      "Epoch 108/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3347 - acc: 0.8827 - val_loss: 0.5608 - val_acc: 0.8123\n",
      "Epoch 109/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3340 - acc: 0.8835 - val_loss: 0.5707 - val_acc: 0.8008\n",
      "Epoch 110/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3333 - acc: 0.8834 - val_loss: 0.5625 - val_acc: 0.8102\n",
      "Epoch 111/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3321 - acc: 0.8830 - val_loss: 0.5692 - val_acc: 0.8110\n",
      "Epoch 112/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3311 - acc: 0.8849 - val_loss: 0.5710 - val_acc: 0.8065\n",
      "Epoch 113/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3303 - acc: 0.8843 - val_loss: 0.5673 - val_acc: 0.8140\n",
      "Epoch 114/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3296 - acc: 0.8839 - val_loss: 0.5687 - val_acc: 0.8077\n",
      "Epoch 115/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3285 - acc: 0.8847 - val_loss: 0.5709 - val_acc: 0.8102\n",
      "Epoch 116/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3274 - acc: 0.8857 - val_loss: 0.5785 - val_acc: 0.8025\n",
      "Epoch 117/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3262 - acc: 0.8854 - val_loss: 0.5678 - val_acc: 0.8102\n",
      "Epoch 118/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3258 - acc: 0.8858 - val_loss: 0.5747 - val_acc: 0.8090\n",
      "Epoch 119/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3252 - acc: 0.8861 - val_loss: 0.5706 - val_acc: 0.8090\n",
      "Epoch 120/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3241 - acc: 0.8861 - val_loss: 0.5724 - val_acc: 0.8112\n",
      "Epoch 121/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3227 - acc: 0.8878 - val_loss: 0.5730 - val_acc: 0.8090\n",
      "Epoch 122/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3221 - acc: 0.8870 - val_loss: 0.5742 - val_acc: 0.8083\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3215 - acc: 0.8871 - val_loss: 0.5733 - val_acc: 0.8110\n",
      "Epoch 124/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3202 - acc: 0.8884 - val_loss: 0.5755 - val_acc: 0.8112\n",
      "Epoch 125/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3195 - acc: 0.8877 - val_loss: 0.5750 - val_acc: 0.8100\n",
      "Epoch 126/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3190 - acc: 0.8886 - val_loss: 0.5770 - val_acc: 0.8115\n",
      "Epoch 127/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3176 - acc: 0.8897 - val_loss: 0.5751 - val_acc: 0.8087\n",
      "Epoch 128/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3170 - acc: 0.8898 - val_loss: 0.5858 - val_acc: 0.8077\n",
      "Epoch 129/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3162 - acc: 0.8903 - val_loss: 0.5876 - val_acc: 0.8043\n",
      "Epoch 130/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3154 - acc: 0.8903 - val_loss: 0.5822 - val_acc: 0.8052\n",
      "Epoch 131/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3142 - acc: 0.8900 - val_loss: 0.5794 - val_acc: 0.8090\n",
      "Epoch 132/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3135 - acc: 0.8907 - val_loss: 0.5866 - val_acc: 0.8062\n",
      "Epoch 133/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3126 - acc: 0.8911 - val_loss: 0.5887 - val_acc: 0.8048\n",
      "Epoch 134/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3115 - acc: 0.8918 - val_loss: 0.5891 - val_acc: 0.8058\n",
      "Epoch 135/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3106 - acc: 0.8917 - val_loss: 0.5878 - val_acc: 0.8085\n",
      "Epoch 136/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3096 - acc: 0.8927 - val_loss: 0.5910 - val_acc: 0.8065\n",
      "Epoch 137/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3087 - acc: 0.8924 - val_loss: 0.5923 - val_acc: 0.8083\n",
      "Epoch 138/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3083 - acc: 0.8924 - val_loss: 0.5857 - val_acc: 0.8080\n",
      "Epoch 139/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3073 - acc: 0.8924 - val_loss: 0.5942 - val_acc: 0.8055\n",
      "Epoch 140/150\n",
      "196/196 [==============================] - 1s 6ms/step - loss: 0.3063 - acc: 0.8935 - val_loss: 0.6003 - val_acc: 0.8027\n",
      "Epoch 141/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3057 - acc: 0.8939 - val_loss: 0.5985 - val_acc: 0.8037\n",
      "Epoch 142/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3047 - acc: 0.8942 - val_loss: 0.6040 - val_acc: 0.7985\n",
      "Epoch 143/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3037 - acc: 0.8937 - val_loss: 0.5947 - val_acc: 0.8035\n",
      "Epoch 144/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3029 - acc: 0.8950 - val_loss: 0.6054 - val_acc: 0.8048\n",
      "Epoch 145/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3024 - acc: 0.8953 - val_loss: 0.5966 - val_acc: 0.8067\n",
      "Epoch 146/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.3011 - acc: 0.8953 - val_loss: 0.6005 - val_acc: 0.8015\n",
      "Epoch 147/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.2999 - acc: 0.8961 - val_loss: 0.5951 - val_acc: 0.8070\n",
      "Epoch 148/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.2992 - acc: 0.8971 - val_loss: 0.5974 - val_acc: 0.8083\n",
      "Epoch 149/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.2984 - acc: 0.8965 - val_loss: 0.6048 - val_acc: 0.8085\n",
      "Epoch 150/150\n",
      "196/196 [==============================] - 1s 5ms/step - loss: 0.2976 - acc: 0.8969 - val_loss: 0.6036 - val_acc: 0.8100\n"
     ]
    }
   ],
   "source": [
    "#  This cell may take several minutes to run\n",
    "random.seed(123)\n",
    "bigger_data_model = models.Sequential()\n",
    "bigger_data_model.add(layers.Dense(50, activation='relu', input_shape=(2000,)))\n",
    "bigger_data_model.add(layers.Dense(25, activation='relu'))\n",
    "bigger_data_model.add(layers.Dense(7, activation='softmax'))\n",
    "\n",
    "bigger_data_model.compile(optimizer='SGD', \n",
    "                          loss='categorical_crossentropy', \n",
    "                          metrics=['acc'])\n",
    "\n",
    "bigger_data_model_val = bigger_data_model.fit(X_train_tokens_bigger,  \n",
    "                                              y_train_lb_bigger,  \n",
    "                                              epochs=150,  \n",
    "                                              batch_size=256,  \n",
    "                                              validation_data=(X_val_tokens_bigger, y_val_lb_bigger))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 2s 1ms/step - loss: 0.2957 - acc: 0.8971\n",
      "Training Loss: 0.296 \n",
      "Training Accuracy: 0.897\n",
      "----------\n",
      "125/125 [==============================] - 0s 2ms/step - loss: 0.6036 - acc: 0.8100\n",
      "Test Loss: 0.604 \n",
      "Test Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "results_train = bigger_data_model.evaluate(X_train_tokens_bigger, y_train_lb_bigger)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = bigger_data_model.evaluate(X_val_tokens_bigger, y_val_lb_bigger)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the same amount of epochs and no regularization technique, you were able to get both better test accuracy and loss. You can still consider early stopping, L1, L2 and dropout here. It's clear that having more data has a strong impact on model performance! \n",
    "\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "* https://github.com/susanli2016/Machine-Learning-with-Python/blob/master/Consumer_complaints.ipynb\n",
    "* https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\n",
    "* https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "\n",
    "\n",
    "## Summary  \n",
    "\n",
    "In this lesson, you built deep learning models using a validation set and used several techniques such as L2 and L1 regularization, dropout regularization, and early stopping to improve the accuracy of your models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
